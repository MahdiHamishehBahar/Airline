{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NwgfFjTcNnk"
      },
      "source": [
        "#***Data Mining Project  1402-1***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcI9i0ojULv8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import shapiro\n",
        "#Disable unwanted warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byvOL77ZcOqI"
      },
      "source": [
        "#Mounting mydrive & Importing data ***(describing and preprocessing)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQqwjq1QTMUf"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/Users/mahdimacbook/Downloads/Airline.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "Rpzjis7mUGtk",
        "outputId": "7bcfbd6c-83c1-404e-ae89-d81f09a02c54"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPZInHlrd146"
      },
      "source": [
        "##Get familiar with df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "jGgjPiWab81r",
        "outputId": "b4424944-99bf-4dd0-f548-48f7acf86122"
      },
      "outputs": [],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJxZGqH-frX7",
        "outputId": "57cf9fa7-4a53-4702-947c-d6a815324bb8"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qngl1qtccC5S",
        "outputId": "f744b41c-59e3-4c4a-fb3f-422b81ffea6e"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "tPTm9zzdcGJN",
        "outputId": "4d43e6bc-db29-412d-cbc1-d6853fb7306a"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckrLW8AOjvl0"
      },
      "source": [
        "Fortunately, there were **no abnormal Ranges** for each columns (unusual min and max) in df. If there were unusual ranges, we could use following code:\n",
        "* **df.replace([np.inf, -np.inf], np.nan, inplace=True)**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDro1l_0gFFJ"
      },
      "source": [
        "##Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yCRQUwqZR5zr",
        "outputId": "4bb5f3e4-0731-4609-bd5b-960014da19ac"
      },
      "outputs": [],
      "source": [
        "# Check for missing values in each column\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Visualize missing values using a heatmap\n",
        "import seaborn as sns\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "fkR0CE3t3dCu",
        "outputId": "370f0301-38a7-4686-e502-847abbc5a0ba"
      },
      "outputs": [],
      "source": [
        "df[df.duplicated()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktzS0xbOfzVg",
        "outputId": "0322f09c-d1f4-4ca2-fd77-309b0ace5c83"
      },
      "outputs": [],
      "source": [
        "#due to high number of records, we can omit 393 null rows (393/129880 is equal to less than 0.3% !).\n",
        "df = df.dropna(axis=0)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y-21CUug3xp",
        "outputId": "beab88f1-0df9-4c62-c7f8-e6c04d14a8b4"
      },
      "outputs": [],
      "source": [
        "#check it\n",
        "print(df.shape,'\\n-----------------')\n",
        "print(df.count(),'\\n----------------')\n",
        "print(df.isna().any(axis=1).sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-ON2v0LhK3o",
        "outputId": "19f97d0f-5dac-4c42-f624-ea5938e0929e"
      },
      "outputs": [],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2pnp3DhkhsMN",
        "outputId": "117a758b-5f36-48f2-9493-77043a028bc5"
      },
      "outputs": [],
      "source": [
        "for i in df:\n",
        "  print(df[i].unique(),'\\n------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elvt2ZdHsGhg"
      },
      "source": [
        "Correcting String Values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpyO_uoarG7D"
      },
      "outputs": [],
      "source": [
        "df['Type of Travel'].replace('Business travel', 'Business Travel', inplace=True)\n",
        "\n",
        "df['Customer Type'].replace('disloyal Customer', 'Disloyal Customer', inplace=True)\n",
        "\n",
        "df['satisfaction'].replace('disloyal Customer', 'Disloyal Customer', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QQY1hfCu1XG"
      },
      "source": [
        "**Outlier Detection Methods:**\n",
        "\n",
        "* Z-Score (Standard Score) Method: This method measures how many standard deviations a data point is from the mean. Data points with a high absolute Z-score are considered outliers.\n",
        "\n",
        "* IQR (Interquartile Range) Method: Calculate the IQR, which is the range between the first quartile (Q1) and the third quartile (Q3). Data points outside the range [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] are considered outliers.\n",
        "\n",
        "* Visual Inspection: Plotting the data using box plots, histograms, or scatter plots can help identify outliers by visually inspecting the data distribution.\n",
        "\n",
        "* Machine Learning Algorithms: Some machine learning algorithms, such as isolation forests and one-class SVM, can be used to detect outliers by modeling the inliers and identifying data points that don't fit the model.\n",
        "\n",
        "* Distance-Based Methods: Calculate distances between data points and look for data points with significantly larger distances from their neighbors.\n",
        "\n",
        "* Statistical Tests: Use statistical tests like the Grubbs' test or the Dixon's test to identify outliers based on a specific significance level.\n",
        "\n",
        "**Outlier Handling Methods:**\n",
        "\n",
        "* Removal: The simplest approach is to remove the outlier data points from the dataset. This can be effective when the outliers are rare and don't carry valuable information.\n",
        "\n",
        "* Capping/Flooring: Capping sets a maximum and minimum threshold for outlier values. Outliers beyond these thresholds are replaced with the threshold values.\n",
        "\n",
        "* Transformation: Apply mathematical transformations to the data, such as log transformations, to reduce the impact of outliers.\n",
        "\n",
        "* Imputation: Replace outliers with missing values or impute them using techniques like mean, median, or regression imputation.\n",
        "\n",
        "* Winsorization: Instead of removing or capping outliers, Winsorization reduces the impact of outliers by replacing them with values near the threshold.\n",
        "\n",
        "* Model-Based Correction: Train a statistical model or machine learning model to predict the correct values for outliers based on the rest of the data.\n",
        "\n",
        "* Data Segmentation: Split the data into segments or clusters and handle outliers separately within each segment.\n",
        "\n",
        "**The choice of an outlier detection and handling method for  DataFrame (df) depends on the specific characteristics of  data, the goals of  analysis, and the potential impact on the quality of  results. Two common methods:**\n",
        "\n",
        "* Z-Score Method: The Z-score method is suitable for data that follows a normal distribution or is approximately normally distributed. It measures how many standard deviations a data point is from the mean. Data points with high absolute Z-scores (e.g., greater than 3) are considered outliers. The advantage of this method is its simplicity and ease of implementation. However, it may not work well for data that is not normally distributed.\n",
        "\n",
        "* IQR (Interquartile Range) Method: The IQR method is robust and can be applied to data with various distributions, including skewed data. It defines outliers based on the range between the first quartile (Q1) and the third quartile (Q3). Data points outside the range [Q1 - 1.5 * IQR, Q3 + 1.5 * IQR] are considered outliers. This method is less sensitive to extreme values than the Z-score method and can handle skewed data effectively.\n",
        "\n",
        "\n",
        "\n",
        "###Outlier detection using   :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j42qQKnx2Wpm"
      },
      "source": [
        "**AGE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Dn1yD2viimGA",
        "outputId": "24b968f8-d236-42f6-830c-6b44097b12c0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Creating plot\n",
        "plt.boxplot(df['Age'])\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmX-PzbN2dMr"
      },
      "source": [
        "--------------------------------------------------------------------------------------------\n",
        "**DISTANCE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "M7HAlZ4TvCYL",
        "outputId": "f4e5866e-dd74-4964-adae-9d8f5711c49c"
      },
      "outputs": [],
      "source": [
        "# Creating plot\n",
        "plt.boxplot(df['Flight Distance'])\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "HKKwBvKv2IQl",
        "outputId": "acdbad70-cc07-4a27-ba90-cfeefda30335"
      },
      "outputs": [],
      "source": [
        "x = df['Flight Distance']\n",
        "plt.hist(x, bins=60 )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q97gcqeNAyD"
      },
      "source": [
        "It is clear from plot that distribution isn't Normal! but we have to do some statistical tests to prove this fact."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "Y-O3hq3W5g2u",
        "outputId": "399020ee-26f9-4aa9-b81a-5a838cc2d5d1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,5))\n",
        "sns.distplot(df['Flight Distance'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "sAggl-wx55jF",
        "outputId": "6973505d-dd88-40ac-b581-b4dc5d615006"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(df['Flight Distance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL1ytcWoKACX"
      },
      "source": [
        "Is Flight distances following a **NORMAL distribution**?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "BS_EWq3vJ_QR",
        "outputId": "27bca442-0069-4e94-ad34-c18ec42095d9"
      },
      "outputs": [],
      "source": [
        "# Plot a histogram to visualize the distribution\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df['Flight Distance'], kde=True)\n",
        "plt.title('Flight Distance Histogram', fontsize=14)\n",
        "plt.xlabel('Flight Distance', fontsize=12)\n",
        "plt.ylabel('Frequency', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# Perform the Shapiro-Wilk normality test\n",
        "statistic, p_value = shapiro(df['Flight Distance'])\n",
        "\n",
        "# Set the significance level (alpha)\n",
        "alpha = 0.05\n",
        "\n",
        "# Check the p-value against alpha\n",
        "if p_value > alpha:\n",
        "    print(f\"The Flight Distance column appears to be normally distributed (p-value={p_value:.4f})\")\n",
        "else:\n",
        "    print(f\"The Flight Distance column does not appear to be normally distributed (p-value={p_value:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O87TiRVFNXal"
      },
      "source": [
        "So after all, we have to use IQR.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sMX6-REHSu0"
      },
      "source": [
        "Age **IQR Based Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNzD0n9E6Jb7",
        "outputId": "1af258a9-129d-4fec-ae1b-8d7991411192"
      },
      "outputs": [],
      "source": [
        "#Finding the IQR\n",
        "percentile25 = df['Flight Distance'].quantile(0.25)\n",
        "percentile75 = df['Flight Distance'].quantile(0.75)\n",
        "\n",
        "#Finding the upper and lower limits\n",
        "iqr = percentile75 - percentile25\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr\n",
        "\n",
        "#Finding outliers\n",
        "df[df['Flight Distance'] > upper_limit]\n",
        "df[df['Flight Distance'] < lower_limit]\n",
        "\n",
        "#Trimming outliers\n",
        "new_df = df[df['Flight Distance'] < upper_limit]\n",
        "\n",
        "print(new_df.shape,upper_limit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukk8WbefHDSV"
      },
      "source": [
        "There are 4319 outliers based on IQR Based Filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "aRH8AFARAvcf",
        "outputId": "6863573c-555e-4dbb-e96c-bd3e50455d3c"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(new_df['Flight Distance'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Zp9YoVtGWH_"
      },
      "source": [
        "The outliers are just irregular compared to the other data points, but can happen, take care of them! So we have to utilize CAPPING."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMs5NYblCN8k"
      },
      "outputs": [],
      "source": [
        "#Capping\n",
        "new_df_cap = df.copy()\n",
        "new_df_cap['Flight Distance'] = np.where(\n",
        "    new_df_cap['Flight Distance'] > upper_limit,\n",
        "    upper_limit,\n",
        "    np.where(\n",
        "        new_df_cap['Flight Distance'] < lower_limit,\n",
        "        lower_limit,\n",
        "        new_df_cap['Flight Distance']\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "GpYMEAKhFjD3",
        "outputId": "5470fab7-7d29-42ad-cfcc-bd7c051f2e07"
      },
      "outputs": [],
      "source": [
        "# Create a new figure with adjusted subplot spacing\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True, gridspec_kw={'wspace': 0.05})\n",
        "\n",
        "\n",
        "sns.boxplot(df['Flight Distance'], ax=axes[0])\n",
        "axes[0].set_title('Box Plot of Flight Distance (Original)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "\n",
        "sns.boxplot(new_df['Flight Distance'], ax=axes[1])\n",
        "axes[1].set_title('Box Plot of Flight Distance (omitted Upper 1.5*IQR)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "\n",
        "sns.boxplot(new_df_cap['Flight Distance'], ax=axes[2])\n",
        "axes[2].set_title('Box Plot of Flight Distance (omitted Upper 1.5*IQR and Capped)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAO1r-gK2jtU"
      },
      "source": [
        "-----------------------------------------------------------------------------------------\n",
        "**DEPARTURE & ARRIVAL DELAY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "MwehCMs1vQE5",
        "outputId": "c573a67f-55e7-40c5-ed37-31f2c418205f"
      },
      "outputs": [],
      "source": [
        "# Creating plot\n",
        "plt.boxplot([df['Departure Delay in Minutes'],df['Arrival Delay in Minutes']])\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "E30xzTGZwJIG",
        "outputId": "7541c560-4bf7-4057-e71e-89365bdfa856"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract the data for the scatter plot\n",
        "x_departure_delay = df['Departure Delay in Minutes']\n",
        "\n",
        "# Create a scatter plot for \"Departure Delay in Minutes\"\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x_departure_delay, range(len(x_departure_delay)), alpha=0.5, c='b', label='Departure Delay')\n",
        "plt.xlabel('Departure Delay in Minutes')\n",
        "plt.ylabel('Index')\n",
        "plt.title('Scatter Plot of Departure Delay in Minutes')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "23Tf1Cwr0Gsm",
        "outputId": "b69daa70-b6b5-40bd-caca-3b76efd3ca90"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "# Extract the data for the scatter plot\n",
        "x_Arrival_delay = df['Arrival Delay in Minutes']\n",
        "\n",
        "# Create a scatter plot for \"Arrival Delay in Minutes\"\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(x_Arrival_delay, range(len(x_Arrival_delay)), alpha=0.5, c='r', label='Arrival Delay')\n",
        "plt.xlabel('Arrival Delay in Minutes')\n",
        "plt.ylabel('Index')\n",
        "plt.title('Scatter Plot of Arrival Delay in Minutes')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pair plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_items = ['Arrival Delay in Minutes', 'Departure Delay in Minutes', 'Flight Distance', 'Age']\n",
        "\n",
        "# Filter the DataFrame for selected items\n",
        "selected_df = df[selected_items + ['satisfaction']]\n",
        "\n",
        "# Create a pair plot\n",
        "pair_plot = sns.pairplot(selected_df, hue='satisfaction', palette={'satisfied': 'green', 'dissatisfied': 'red'})\n",
        "\n",
        "# Add a legend\n",
        "pair_plot.add_legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "AdBgzMsQ1Q7R",
        "outputId": "a5fd89bc-708f-42de-ad43-c17ce2859502"
      },
      "outputs": [],
      "source": [
        "x = df['Departure Delay in Minutes']\n",
        "plt.hist(x, bins=60 )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "Q6BpMCjf1qzU",
        "outputId": "8c25ee71-cb31-4157-cbbb-d0b59b0b3b9c"
      },
      "outputs": [],
      "source": [
        "x = df['Arrival Delay in Minutes']\n",
        "plt.hist(x, bins=60 )\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLuoB_-TNoFm"
      },
      "source": [
        "They don't appear to be normally distributed, but we have to prove it.\n",
        "\n",
        "Are  \"Arrival Delay in Minutes\" and \"Departure Delay in Minutes\"  following **NORMAL distribution**?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 859
        },
        "id": "x1Egkcny5Dw2",
        "outputId": "93806e99-dcfc-4b40-9b88-15d4b98b4ebe"
      },
      "outputs": [],
      "source": [
        "# Columns to test\n",
        "columns_to_test = ['Arrival Delay in Minutes', 'Departure Delay in Minutes']\n",
        "\n",
        "for column in columns_to_test:\n",
        "    # Plot a histogram to visualize the distribution\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.histplot(df[column], kde=True)\n",
        "    plt.title(f'{column} Histogram', fontsize=14)\n",
        "    plt.xlabel(column, fontsize=12)\n",
        "    plt.ylabel('Frequency', fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "    # Perform the Shapiro-Wilk normality test\n",
        "    statistic, p_value = shapiro(df[column])\n",
        "\n",
        "    # Set the significance level (alpha)\n",
        "    alpha = 0.05\n",
        "\n",
        "    # Check the p-value against alpha\n",
        "    if p_value > alpha:\n",
        "        print(f\"The {column} column appears to be normally distributed (p-value={p_value:.4f})\")\n",
        "    else:\n",
        "        print(f\"The {column} column does not appear to be normally distributed (p-value={p_value:.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKdQ8GV_PXqy"
      },
      "source": [
        "Arrival Delay in Minutes **IQR Based Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMliPma4OZ7z",
        "outputId": "31308089-5609-4059-a002-4cdac34f6aff"
      },
      "outputs": [],
      "source": [
        "#Finding the IQR\n",
        "percentile25 = df['Arrival Delay in Minutes'].quantile(0.25)\n",
        "percentile75 = df['Arrival Delay in Minutes'].quantile(0.75)\n",
        "\n",
        "#Finding the upper and lower limits\n",
        "iqr = percentile75 - percentile25\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr\n",
        "\n",
        "#Finding outliers\n",
        "df[df['Arrival Delay in Minutes'] > upper_limit]\n",
        "df[df['Arrival Delay in Minutes'] < lower_limit]\n",
        "\n",
        "#Trimming outliers\n",
        "new_df = df[df['Arrival Delay in Minutes'] < upper_limit]\n",
        "\n",
        "print(new_df.shape,upper_limit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zn37XDTTl5V"
      },
      "source": [
        "There are 17492 outliers based on IQR Based Filtering.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5XJCWuLTL8h",
        "outputId": "954367d0-ac5e-4951-f5a9-b6dea2831b14"
      },
      "outputs": [],
      "source": [
        "#Capping\n",
        "new_df_cap = df.copy()\n",
        "new_df_cap['Arrival Delay in Minutes'] = np.where(\n",
        "    new_df_cap['Arrival Delay in Minutes'] > upper_limit,\n",
        "    upper_limit,\n",
        "    np.where(\n",
        "        new_df_cap['Arrival Delay in Minutes'] < lower_limit,\n",
        "        lower_limit,\n",
        "        new_df_cap['Arrival Delay in Minutes']\n",
        "    )\n",
        ")\n",
        "new_df_cap.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "lLNh5klBT-zB",
        "outputId": "5d8756fa-2ad1-4365-9c3b-3beb4223b1e3"
      },
      "outputs": [],
      "source": [
        "# Create a new figure with adjusted subplot spacing\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True, gridspec_kw={'wspace': 0.1})\n",
        "\n",
        "\n",
        "sns.boxplot(df['Arrival Delay in Minutes'], ax=axes[0])\n",
        "axes[0].set_title('Box Plot of Arrival Delay in Minutes (Original)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "\n",
        "sns.boxplot(new_df['Arrival Delay in Minutes'], ax=axes[1])\n",
        "axes[1].set_title('Box Plot of Arrival Delay in Minutes (omitted Upper 1.5*IQR)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "\n",
        "sns.boxplot(new_df_cap['Arrival Delay in Minutes'], ax=axes[2])\n",
        "axes[2].set_title('Box Plot of Arrival Delay in Minutes (omitted Upper 1.5*IQR and Capped)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "9DHnY8L1U3IN",
        "outputId": "6814f81c-4aad-4e91-aa7f-4305eee60cc6"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(new_df['Arrival Delay in Minutes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "gl9xEfbUWKs7",
        "outputId": "8f0b254b-06d5-49fc-e13a-a527ab8b9adc"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(new_df_cap['Arrival Delay in Minutes'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl4OfkCAlLqy"
      },
      "source": [
        "Departure Delay in Minutes **IQR Based Filtering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl8O8re2W5HH",
        "outputId": "81b26f6e-223d-4c49-b8e0-96f062f1658c"
      },
      "outputs": [],
      "source": [
        "#Finding the IQR\n",
        "percentile25 = df['Departure Delay in Minutes'].quantile(0.25)\n",
        "percentile75 = df['Departure Delay in Minutes'].quantile(0.75)\n",
        "\n",
        "#Finding the upper and lower limits\n",
        "iqr = percentile75 - percentile25\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr\n",
        "\n",
        "#Finding outliers\n",
        "df[df['Departure Delay in Minutes'] > upper_limit]\n",
        "df[df['Departure Delay in Minutes'] < lower_limit]\n",
        "\n",
        "#Trimming outliers\n",
        "new_df = df[df['Departure Delay in Minutes'] < upper_limit]\n",
        "\n",
        "print(new_df.shape,upper_limit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMo2d6xNl6jD"
      },
      "source": [
        "There are 18512 outliers based on IQR Based Filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLgawHrLlOoF",
        "outputId": "e8eeb0e4-95b8-4ea2-bd28-322f29fac0bd"
      },
      "outputs": [],
      "source": [
        "#Capping\n",
        "new_df_cap = df.copy()\n",
        "new_df_cap['Departure Delay in Minutes'] = np.where(\n",
        "    new_df_cap['Departure Delay in Minutes'] > upper_limit,\n",
        "    upper_limit,\n",
        "    np.where(\n",
        "        new_df_cap['Departure Delay in Minutes'] < lower_limit,\n",
        "        lower_limit,\n",
        "        new_df_cap['Departure Delay in Minutes']\n",
        "    )\n",
        ")\n",
        "new_df_cap.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "KtBv4hdKltib",
        "outputId": "d798c06b-f98f-462b-9cbe-ee9960ec1c5e"
      },
      "outputs": [],
      "source": [
        "# Create a new figure with adjusted subplot spacing\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True, gridspec_kw={'wspace': 0.1})\n",
        "\n",
        "\n",
        "sns.boxplot(df['Departure Delay in Minutes'], ax=axes[0])\n",
        "axes[0].set_title('Box Plot of Departure Delay in Minutes (Original)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "\n",
        "sns.boxplot(new_df['Departure Delay in Minutes'], ax=axes[1])\n",
        "axes[1].set_title('Box Plot of Departure Delay in Minutes (omitted Upper 1.5*IQR)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "\n",
        "sns.boxplot(new_df_cap['Departure Delay in Minutes'], ax=axes[2])\n",
        "axes[2].set_title('Box Plot of Departure Delay in Minutes (omitted Upper 1.5*IQR and Capped)', fontsize=10)  # Adjust the font size\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "BQhw4olDmTNr",
        "outputId": "78be9b83-4965-4aba-f2c6-04cec398c587"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(new_df['Departure Delay in Minutes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "vupuoyRSmYou",
        "outputId": "546d7fbe-a9f8-4aa2-ec2a-8378180affcf"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(new_df_cap['Departure Delay in Minutes'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkJkLFDdnjNq"
      },
      "source": [
        "**Applying all methods on Original df:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUfO9sNAnjax"
      },
      "outputs": [],
      "source": [
        "#Finding the IQR\n",
        "percentile25 = df['Flight Distance'].quantile(0.25)\n",
        "percentile75 = df['Flight Distance'].quantile(0.75)\n",
        "\n",
        "#Finding the upper and lower limits\n",
        "iqr = percentile75 - percentile25\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr\n",
        "\n",
        "#Capping\n",
        "df['Flight Distance'] = np.where(\n",
        "    df['Flight Distance'] > upper_limit,\n",
        "    upper_limit,\n",
        "    np.where(\n",
        "        df['Flight Distance'] < lower_limit,\n",
        "        lower_limit,\n",
        "        df['Flight Distance']\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Finding the IQR\n",
        "percentile25 = df['Arrival Delay in Minutes'].quantile(0.25)\n",
        "percentile75 = df['Arrival Delay in Minutes'].quantile(0.75)\n",
        "\n",
        "#Finding the upper and lower limits\n",
        "iqr = percentile75 - percentile25\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr\n",
        "\n",
        "#Capping\n",
        "df['Arrival Delay in Minutes'] = np.where(\n",
        "    df['Arrival Delay in Minutes'] > upper_limit,\n",
        "    upper_limit,\n",
        "    np.where(\n",
        "        df['Arrival Delay in Minutes'] < lower_limit,\n",
        "        lower_limit,\n",
        "        df['Arrival Delay in Minutes']\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Finding the IQR\n",
        "percentile25 = df['Departure Delay in Minutes'].quantile(0.25)\n",
        "percentile75 = df['Departure Delay in Minutes'].quantile(0.75)\n",
        "\n",
        "#Finding the upper and lower limits\n",
        "iqr = percentile75 - percentile25\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr\n",
        "\n",
        "#Capping\n",
        "df['Departure Delay in Minutes'] = np.where(\n",
        "    df['Departure Delay in Minutes'] > upper_limit,\n",
        "    upper_limit,\n",
        "    np.where(\n",
        "        df['Departure Delay in Minutes'] < lower_limit,\n",
        "        lower_limit,\n",
        "        df['Departure Delay in Minutes']\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "ZhdQevwdns6c",
        "outputId": "d3d28ebc-884d-405e-d59c-7eafbe529e4e"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "SXXYhsewo3Me",
        "outputId": "cdff128d-9fd0-4359-c2f3-091cdebcc9b5"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7cNSBpgq9umu",
        "outputId": "05a38856-c344-420d-fe95-7e42a09cf919"
      },
      "outputs": [],
      "source": [
        "dec = pd.DataFrame()\n",
        "dec['decimals'] = df['Flight Distance'].map(lambda x: str(x).split('.')[1]).apply(lambda x: x)\n",
        "dec['decimals'].max()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7zm8G__Fl5Y"
      },
      "source": [
        "All the numbers in Flight Distance are integer!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOwH_IhBDmx4"
      },
      "outputs": [],
      "source": [
        "df['Flight Distance'] = df['Flight Distance'].astype('int64')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ-T5RZnDpsB",
        "outputId": "b56b243d-eb3c-4339-8778-7cdd16827bbb"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrcQPYZWa1G-"
      },
      "source": [
        "##Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s9HaCi_8bGkS",
        "outputId": "aa8f45d6-f3e4-4b70-b073-2f02db57a0c4"
      },
      "outputs": [],
      "source": [
        "# Set the style for Seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Iterate through each column in the DataFrame\n",
        "for column in df.columns:\n",
        "    # Create a new figure for each column\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    # Choose the appropriate plot based on the data type of the column\n",
        "    if pd.api.types.is_numeric_dtype(df[column]):\n",
        "        # For numeric columns, create a histogram\n",
        "        sns.histplot(df[column], kde=True)\n",
        "        plt.title(f'Histogram of {column}', fontsize=16)\n",
        "        plt.xlabel(column, fontsize=14)\n",
        "        plt.ylabel('Frequency', fontsize=14)\n",
        "    else:\n",
        "        # For categorical columns, create a countplot\n",
        "        sns.countplot(x=column, data=df, palette='viridis')\n",
        "        plt.title(f'Countplot of {column}', fontsize=16)\n",
        "        plt.xlabel(column, fontsize=14)\n",
        "        plt.ylabel('Count', fontsize=14)\n",
        "\n",
        "    # Show the plot for the current column\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzgoW1ECA0qD"
      },
      "outputs": [],
      "source": [
        "def plot_pie_chart(df, column, chart_size=(8, 8), label_font_size=12):\n",
        "    \"\"\"\n",
        "    Create a pie chart for a categorical column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame\n",
        "    - column: str, the column for which to create the pie chart\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if the column exists in the DataFrame\n",
        "    if column not in df.columns:\n",
        "        print(f\"Column '{column}' not found in the DataFrame.\")\n",
        "        return\n",
        "\n",
        "    # Get value counts for the column\n",
        "    value_counts = df[column].value_counts()\n",
        "\n",
        "    # Create a pie chart with autopct for auto-formatting\n",
        "    plt.figure(figsize=chart_size)\n",
        "    plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=45,\n",
        "            textprops={'fontsize': label_font_size}, colors=sns.color_palette('viridis'))\n",
        "    plt.title(f'Pie Chart for {column}', fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#----------------------------------------------------------------------------\n",
        "\n",
        "def plot_bar_chart(df, column):\n",
        "    \"\"\"\n",
        "    Create a bar chart for a categorical column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame\n",
        "    - column: str, the column for which to create the bar chart\n",
        "    \"\"\"\n",
        "\n",
        "    # Get value counts for the column\n",
        "    value_counts = df[column].value_counts()\n",
        "\n",
        "    # Create a bar chart\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=value_counts.index, y=value_counts, palette='viridis')\n",
        "    plt.title(f'Bar Chart for {column}', fontsize=16)\n",
        "    plt.xlabel(column, fontsize=14)\n",
        "    plt.ylabel('Count', fontsize=14)\n",
        "    plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better visibility\n",
        "    plt.show()\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def plot_scatter_chart(df, x_column, y_column):\n",
        "    \"\"\"\n",
        "    Create a scatter plot for two numerical columns in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame\n",
        "    - x_column: str, the column for the x-axis\n",
        "    - y_column: str, the column for the y-axis\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a scatter plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.scatterplot(x=df[x_column], y=df[y_column], color='blue', alpha=0.7)\n",
        "    plt.title(f'Scatter Plot: {x_column} vs {y_column}', fontsize=16)\n",
        "    plt.xlabel(x_column, fontsize=14)\n",
        "    plt.ylabel(y_column, fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "\n",
        "def plot_line_chart(df, x_column, y_column):\n",
        "    \"\"\"\n",
        "    Create a line plot for a numerical column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame\n",
        "    - x_column: str, the column for the x-axis\n",
        "    - y_column: str, the column for the y-axis\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a line plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.lineplot(x=df[x_column], y=df[y_column], color='green')\n",
        "    plt.title(f'Line Plot: {y_column} over {x_column}', fontsize=16)\n",
        "    plt.xlabel(x_column, fontsize=14)\n",
        "    plt.ylabel(y_column, fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def plot_histogram(df, column):\n",
        "    \"\"\"\n",
        "    Create a histogram plot for a numerical column in a DataFrame.\n",
        "\n",
        "    Parameters:\n",
        "    - df: DataFrame\n",
        "    - column: str, the column for the histogram\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a histogram plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(df[column], kde=True, color='skyblue')\n",
        "    plt.title(f'Histogram Plot: {column}', fontsize=16)\n",
        "    plt.xlabel(column, fontsize=14)\n",
        "    plt.ylabel('Frequency', fontsize=14)\n",
        "    plt.show()\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def plot_violin_plot(dataframe, x_col, y_col):\n",
        "    \"\"\"\n",
        "    Creates a violin plot to visualize the distribution of a numerical variable across different categories.\n",
        "\n",
        "    A violin plot is a hybrid of a box plot and a kernel density plot, which shows peaks in the data. It is\n",
        "    used to visualize the distribution of numerical data. Unlike a box plot that can only show summary\n",
        "    statistics, violin plots depict summary statistics and the density of each variable.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe: pandas DataFrame\n",
        "    - x_col: Name of the categorical variable (column on the x-axis)\n",
        "    - y_col: Name of the numerical variable (column being visualized)\n",
        "\n",
        "    Returns:\n",
        "    - None (displays the violin plot)\n",
        "    \"\"\"\n",
        "    sns.violinplot(x=x_col, y=y_col, data=dataframe)\n",
        "    plt.title(f'Violin Plot of {y_col} across {x_col}')\n",
        "    plt.show()\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "def plot_grouped_bar(dataframe, x_col, y_col, hue_col):\n",
        "    \"\"\"\n",
        "    Creates a grouped bar plot to show the relationship between two categorical variables.\n",
        "\n",
        "    Parameters:\n",
        "    - dataframe: pandas DataFrame\n",
        "    - x_col: Name of the first categorical variable (x-axis)\n",
        "    - y_col: Name of the numerical variable (y-axis)\n",
        "    - hue_col: Name of the second categorical variable for grouping\n",
        "\n",
        "    Returns:\n",
        "    - None (displays the grouped bar plot)\n",
        "    \"\"\"\n",
        "    sns.barplot(x=x_col, y=y_col, hue=hue_col, data=dataframe)\n",
        "    plt.title(f'Grouped Bar Plot of {y_col} across {x_col} grouped by {hue_col}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "vRfO3ee7bGzl",
        "outputId": "985bbc91-ec4c-4613-8c78-8e8c4abcb35e"
      },
      "outputs": [],
      "source": [
        "plot_pie_chart(df, 'satisfaction', chart_size=(4, 4), label_font_size=11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "i8IXjvxHbHFP",
        "outputId": "f9f32dd4-ebc5-4bb6-945c-0aee4b417e71"
      },
      "outputs": [],
      "source": [
        "# Creating age groups\n",
        "bins = [0, 18, 30, 50, 70, 90]  # Define  age group bins\n",
        "labels = ['Younge', 'YoungeAdult', 'Adult', 'MiddleAge', 'Elderly']  # Labels for the age groups\n",
        "\n",
        "df['Age Group'] = pd.cut(df['Age'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "plot_pie_chart(df, 'Age Group', chart_size=(5, 5), label_font_size=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "tuqgGdUCbHLe",
        "outputId": "4d14ab4b-3ec1-47ef-e4a5-f5593b44e6a5"
      },
      "outputs": [],
      "source": [
        "plot_bar_chart(df,'Class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 670
        },
        "id": "yit8g-I-bHON",
        "outputId": "3a46953f-27c2-44a0-9ca6-72c18f7d1625"
      },
      "outputs": [],
      "source": [
        "plot_bar_chart(df,'Customer Type')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "1WldiwN-LIca",
        "outputId": "3c08b7b8-a3b4-4107-f3f6-1458a12d3352"
      },
      "outputs": [],
      "source": [
        "plot_histogram(df,'Age Group')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "2z5GYd4pLIjB",
        "outputId": "f4f2bf42-7d09-4f13-becc-0f66085302b6"
      },
      "outputs": [],
      "source": [
        "plot_violin_plot(df,'Age','satisfaction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "u-f1yroKLIm7",
        "outputId": "02644de2-7b8f-4077-ff4b-3fcaddcea733"
      },
      "outputs": [],
      "source": [
        "plot_violin_plot(df,'Food and drink','Seat comfort')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "IJrFfwSuLMtq",
        "outputId": "12d28819-2732-4708-9f3b-cda791919dcb"
      },
      "outputs": [],
      "source": [
        "plot_violin_plot(df,'Seat comfort','satisfaction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "UFzm8VABLMyC",
        "outputId": "b07ac4cb-d94f-40a1-91c1-56ad9a87d31e"
      },
      "outputs": [],
      "source": [
        "plot_violin_plot(df,'Flight Distance','Class')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "vz67vd4ELQPw",
        "outputId": "9ff19851-82d7-4fed-99ef-4fb2a332bcc3"
      },
      "outputs": [],
      "source": [
        "plot_violin_plot(df,'Leg room service','Age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "tmkMlezOLQT5",
        "outputId": "05854aab-4913-4534-8ef8-d73a90c24175"
      },
      "outputs": [],
      "source": [
        "plot_violin_plot(df,'Leg room service','Age')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "RTPB2ssnLM2m",
        "outputId": "701191c2-581e-4e72-ee63-c0673268a23c"
      },
      "outputs": [],
      "source": [
        "plot_grouped_bar(df, \"Departure/Arrival time convenient\", \"Seat comfort\", \"satisfaction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "CywAQqPvLVUj",
        "outputId": "3f511068-5bed-41c5-da64-f9ecb68c5df3"
      },
      "outputs": [],
      "source": [
        "plot_grouped_bar(df, \"Departure/Arrival time convenient\", \"On-board service\", \"Class\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "cvryleTn2vCx",
        "outputId": "5d738a05-1a44-42ea-fd2f-442738aaae4c"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "category_columns = ['Type of Travel', 'Class']\n",
        "\n",
        "# Create a treemap using plotly express\n",
        "fig = px.treemap(df, path=category_columns)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "ZqE4LlkO6gcV",
        "outputId": "2275f9e3-f860-485e-a693-751133a3d095"
      },
      "outputs": [],
      "source": [
        "value_column = 'Flight Distance'\n",
        "category_columns = ['Type of Travel', 'Class']\n",
        "\n",
        "# Create a treemap using plotly express\n",
        "fig = px.treemap(df, path=category_columns, values=value_column, title=f'Treemap of {value_column} by {\", \".join(category_columns)}')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5FRb5TU-f5t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gzKaDH6CXqa"
      },
      "outputs": [],
      "source": [
        "# List of columns containing scores\n",
        "score_columns = ['Seat comfort', 'Departure/Arrival time convenient',\n",
        "       'Food and drink', 'Gate location', 'Inflight wifi service',\n",
        "       'Inflight entertainment', 'Online support', 'Ease of Online booking',\n",
        "       'On-board service', 'Leg room service', 'Baggage handling',\n",
        "       'Checkin service', 'Cleanliness', 'Online boarding']\n",
        "\n",
        "# Create a new column 'Total_Score' with the sum of scores from specified columns\n",
        "df['Total_Score'] = df[score_columns].sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsCKmMHt25cE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi02vdJ98PRa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b3xaSjL8PYe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1MzOPrFSm70"
      },
      "source": [
        "###**Correlation Matrix**\n",
        "\n",
        "*   Perfect Correlation:\n",
        "\n",
        "**1.0**: A correlation coefficient of 1.0 indicates a perfect positive linear relationship between two variables. If one variable increases, the other variable also increases proportionally.\n",
        "\n",
        "**-1.0**: A correlation coefficient of -1.0 indicates a perfect negative linear relationship. If one variable increases, the other variable decreases proportionally.\n",
        "\n",
        "*   Strong Correlation:\n",
        "\n",
        "**0.7 to 0.9** (positive or negative): Generally considered a strong correlation. Indicates a significant relationship between the variables.\n",
        "\n",
        "*   Moderate Correlation:\n",
        "\n",
        "**0.4 to 0.6**(positive or negative): Moderate correlation. The relationship is noticeable but not as strong.\n",
        "\n",
        "so we can set criteria for it:\n",
        "\n",
        "* 1.00 to 0.90 (or -1.00 to -0.90): Very strong positive (or negative) correlation.\n",
        "* 0.90 to 0.70 (or -0.90 to -0.70): Strong positive (or negative) correlation.\n",
        "* 0.70 to 0.50 (or -0.70 to -0.50): Moderate positive (or negative) correlation.\n",
        "* 0.50 to 0.30 (or -0.50 to -0.30): Weak positive (or negative) correlation.\n",
        "\n",
        "https://doi.org/10.48550/arXiv.2303.01835"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "7LAxj4iiGB2q",
        "outputId": "c0cc5bd7-3e33-43a1-cd04-f5ebba7beefa"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Display the correlation matrix with a color gradient\n",
        "correlation_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKtilclIazSv"
      },
      "outputs": [],
      "source": [
        "#  'preprocessed_df' is  preprocessed DataFrame\n",
        "#preprocessed_df.to_csv('preprocessed_data.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "Ipu_RqoxIfH4",
        "outputId": "17165004-a160-43ab-bd16-c81c313a9a67"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p0jSDkZWnBg"
      },
      "source": [
        "\n",
        "\n",
        "Changing Categorical Data to Numerical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jhDzDiQazXw"
      },
      "outputs": [],
      "source": [
        "dfc = df.copy()\n",
        "\n",
        "#Method one for Label Encoding\n",
        "dfc.Class.replace('Eco', 0, inplace=True)\n",
        "dfc.Class.replace('Eco Plus', 1, inplace=True)\n",
        "dfc.Class.replace('Business', 2, inplace=True)\n",
        "dfc.Class.astype('int64')\n",
        "\n",
        "dfc['Customer Type'].replace('Loyal Customer', 1, inplace=True)\n",
        "dfc['Customer Type'].replace('Disloyal Customer', 0, inplace=True)\n",
        "dfc['Customer Type'].astype('int64')\n",
        "\n",
        "#Method two for Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "dfc['satisfaction'] = label_encoder.fit_transform(dfc['satisfaction'])\n",
        "dfc['Type of Travel'] = label_encoder.fit_transform(dfc['Type of Travel'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "qGzbqmiOdEeG",
        "outputId": "424f89b1-9bb9-46e3-b417-4bbff4b42c08"
      },
      "outputs": [],
      "source": [
        "dfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aahbTiEkMBV6",
        "outputId": "dca7abda-c5e8-4817-8285-2e3c7ffc93b0"
      },
      "outputs": [],
      "source": [
        "dfc[dfc['satisfaction']==1].count()/dfc[dfc['satisfaction']==0].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBzfjOW57vnf"
      },
      "outputs": [],
      "source": [
        "df1 = dfc.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIMozApQ9sRE"
      },
      "source": [
        "### Data visualization 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "0Q-3lWBk9sYW",
        "outputId": "40d74572-eb6e-4b87-c8df-13e33e3ea918"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "fig = px.scatter(dfc, y='Total_Score', x='Class', color='satisfaction')\n",
        "fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "oL45wnIsDfcS",
        "outputId": "b35df771-cc1a-40e4-95c1-4c3741cbba91"
      },
      "outputs": [],
      "source": [
        "x_column = 'Age'\n",
        "y_column = 'Flight Distance'\n",
        "color_column = 'satisfaction'\n",
        "\n",
        "# Create a hexbin plot with color-coded points\n",
        "plt.hexbin(dfc[x_column], dfc[y_column], gridsize=(15, 15), cmap='viridis', C=dfc[color_column], alpha=0.8)\n",
        "plt.xlabel(x_column)\n",
        "plt.ylabel(y_column)\n",
        "plt.title(f'Hexbin Plot of {x_column} vs {y_column} (Color-coded by {color_column})')\n",
        "plt.colorbar(label=color_column)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "l6HSqGzhJvvk",
        "outputId": "fe7bd71e-274d-443a-9de2-961959e61850"
      },
      "outputs": [],
      "source": [
        "value_column = 'satisfaction'\n",
        "category_columns = ['Age Group', 'Total_Score']\n",
        "\n",
        "# Create a treemap using plotly express\n",
        "fig = px.treemap(dfc, path=category_columns, values=value_column, title=f'Treemap of {value_column} by {\", \".join(category_columns)}')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "MUUBtsuQP48t",
        "outputId": "98ffb130-306d-4690-d483-f933b74552a3"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='Age Group', y='Total_Score', data=dfc)\n",
        "plt.title('Box Plot of Total_Score by Age Group')\n",
        "plt.xlabel('Age Group')\n",
        "plt.ylabel('Total_Score')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "DHIebNJfUcOV",
        "outputId": "b865057c-3396-491b-8674-5bdc63ff191f"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='satisfaction', y='Total_Score', data=dfc)\n",
        "plt.title('Box Plot of satisfaction by Total_Score')\n",
        "plt.xlabel('satisfaction')\n",
        "plt.ylabel('Total_Score')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "RQt5eSGFXbUL",
        "outputId": "14179466-f7fc-41a0-93a1-18b116a4f9b3"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(x='satisfaction', y='Flight Distance', data=dfc)\n",
        "plt.title('Box Plot of satisfaction by Flight Distance')\n",
        "plt.xlabel('satisfaction')\n",
        "plt.ylabel('Flight Distance')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pair plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "selected_items = ['Arrival Delay in Minutes', 'Departure Delay in Minutes', 'Flight Distance', 'Age']\n",
        "\n",
        "# Filter the DataFrame for selected items\n",
        "selected_df = df[selected_items + ['satisfaction']]\n",
        "\n",
        "# Create a pair plot\n",
        "pair_plot = sns.pairplot(selected_df, hue='satisfaction', palette={'satisfied': 'green', 'dissatisfied': 'red'})\n",
        "\n",
        "# Add a legend\n",
        "pair_plot.add_legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln33BHRnm9PG"
      },
      "outputs": [],
      "source": [
        "dfc = dfc.drop('Age Group', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "z-pGLAnZnCR6",
        "outputId": "dce5bd98-dafc-4b58-892d-41aa67884da0"
      },
      "outputs": [],
      "source": [
        "dfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP5epJDmKDN8"
      },
      "outputs": [],
      "source": [
        "df = dfc.copy()\n",
        "df1 = dfc.copy()\n",
        "df2 = dfc.copy()\n",
        "df3 = dfc.copy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBG5fVxHgcD0"
      },
      "source": [
        "Skew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fueX8n0ugcYZ",
        "outputId": "0984759e-341e-425c-ad9f-3a1958c59ada"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "numeric_cols = dfc.select_dtypes(include=['number']).columns\n",
        "\n",
        "# Calculate skewness for each numerical column\n",
        "skewness = dfc[numeric_cols].apply(lambda x: x.skew())\n",
        "\n",
        "# Display variables with skewness greater than a certain threshold (e.g., 1)\n",
        "skewed_vars = skewness[abs(skewness) > 1]\n",
        "print(\"Skewed Variables:\")\n",
        "print(skewed_vars)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD1Urk1HIY8G"
      },
      "source": [
        "Imbalanced Data and Scaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EW048YYPIZWI"
      },
      "outputs": [],
      "source": [
        "X = dfc.drop(columns = ['satisfaction'])\n",
        "y = dfc['satisfaction']\n",
        "\n",
        "#Using SMOTE to balance the Data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 42)\n",
        "X, y = sm.fit_resample(X, y)\n",
        "pd.Series(y).value_counts()\n",
        "dfc = X.join(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbmLVrrXYwES"
      },
      "outputs": [],
      "source": [
        "#Saving names for rename them after scalling\n",
        "c = dfc.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H--B-ypLWXub"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "Scaler = MinMaxScaler()\n",
        "dfc = Scaler.fit_transform(dfc)\n",
        "\n",
        "dfc = pd.DataFrame(dfc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "a2sKBhWpKF7f",
        "outputId": "4703fe70-cc08-46cd-d2d7-dc785f563361"
      },
      "outputs": [],
      "source": [
        "dfc.columns = c\n",
        "dfc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PR9Cr2PYdcUl",
        "outputId": "5015c814-3250-430e-ee16-6b1f39df476f"
      },
      "outputs": [],
      "source": [
        "correlation_matrix = dfc.corr()\n",
        "\n",
        "# Display the correlation matrix with a color gradient\n",
        "correlation_matrix.style.background_gradient(cmap='coolwarm').set_precision(2)\n",
        "\n",
        "plt.figure(figsize=(20, 16))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Save the heatmap as an image\n",
        "plt.savefig('correlation_heatmap.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "2AtEs9V3ZUvT",
        "outputId": "39365d00-6977-4ec0-fa99-620155f80972"
      },
      "outputs": [],
      "source": [
        "class_counts = dfc['Customer Type'].value_counts()\n",
        "\n",
        "# Plot a pie chart\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(class_counts, labels=class_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('viridis'))\n",
        "plt.title('Pie Chart for Customer Type', fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "ucXj4O44VLkh",
        "outputId": "72bb6105-4343-4c05-fcf6-e6a881895f0f"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "sns.regplot(x = \"Inflight entertainment\", y = \"satisfaction\", data = dfc, ci = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "KFEHMDgWu3Yy",
        "outputId": "b16bba63-8200-4dc4-c79b-cd7ecc6a62a6"
      },
      "outputs": [],
      "source": [
        "sns.regplot(x = \"Class\", y = \"Type of Travel\", data = dfc, ci = None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "dhA4FLiWvQlw",
        "outputId": "ee29b24f-761c-4409-e0e3-28afb2f538f8"
      },
      "outputs": [],
      "source": [
        "sns.regplot(x = \"Seat comfort\", y = \"Food and drink\", data = df, ci = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwW1EM-78BYF"
      },
      "source": [
        "###Feature Engineering\n",
        "\n",
        "*  Feature importance:\n",
        "\n",
        " It is often assessed using machine learning algorithms that provide insights into which features contribute more to the predictive performance. Random Forest is a popular algorithm for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVBODsf_7dUZ",
        "outputId": "86f12f0f-c917-45ce-d68e-e4ca8e129d70"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Separate features and target variable\n",
        "X = dfc.drop('satisfaction', axis=1)\n",
        "y = dfc['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a RandomForestClassifier\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature importances\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Display the feature importances\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importance_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZARKOzBBZ3m"
      },
      "source": [
        "###Feature selection\n",
        "\n",
        "Principal Component Analysis (PCA): Linear transformation that projects the data onto a lower-dimensional subspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "VDks_HxvAPDN",
        "outputId": "a352d611-8d9b-49a6-a687-524500257090"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Separate the features from the target variable\n",
        "X = dfc.drop('satisfaction', axis=1)\n",
        "y = dfc['satisfaction']\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA with the desired number of components\n",
        "num_components = 20  # Choose the number of components you want\n",
        "pca = PCA(n_components=num_components)\n",
        "principal_components = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a DataFrame with the principal components\n",
        "columns = [f'PC{i+1}' for i in range(num_components)]\n",
        "pc_df = pd.DataFrame(data=principal_components, columns=columns)\n",
        "\n",
        "# Concatenate the principal components with the target variable\n",
        "final_df = pd.concat([pc_df, y], axis=1)\n",
        "\n",
        "# Visualize the explained variance ratio\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "print(f\"Explained Variance Ratio: {explained_variance_ratio}\")\n",
        "\n",
        "# Plot the cumulative explained variance\n",
        "cumulative_explained_variance = explained_variance_ratio.cumsum()\n",
        "plt.plot(range(1, num_components + 1), cumulative_explained_variance, marker='o')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance vs. Number of Components')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "q-4y03NJCods",
        "outputId": "3ec4b434-2d2e-46ce-c129-dabe81922a1d"
      },
      "outputs": [],
      "source": [
        "loadings_pc1 = pca.components_[0]\n",
        "loadings_df = pd.DataFrame({'Feature': X.columns, 'Loading_PC1': loadings_pc1})\n",
        "loadings_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvJiYQxIqbaW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuZcphIFO2PP"
      },
      "source": [
        "##REGRESSION (satisfaction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q8bFzdA4vPDP"
      },
      "source": [
        "***Train and Test split***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQGfzfpVvODj",
        "outputId": "de76e0d0-629d-4db9-8f75-e330d86171b9"
      },
      "outputs": [],
      "source": [
        "X = dfc.drop('satisfaction', axis=1)  # Features\n",
        "y = dfc['satisfaction']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the shapes of the resulting sets\n",
        "print(\"Training set:\", X_train.shape, y_train.shape)\n",
        "print(\"Testing set:\", X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syIdmuWt3W5N"
      },
      "source": [
        "####Linear Reg\n",
        "Inflight entertainment & satisfaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdVhmBS3kaV6",
        "outputId": "b881e984-a5cb-4c7c-bb0e-96e03d5ac64c"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "regr = linear_model.LinearRegression()\n",
        "train_x = np.asanyarray(X_train[['Inflight entertainment']])\n",
        "train_y = np.asanyarray(y_train)\n",
        "regr.fit (train_x, train_y)\n",
        "\n",
        "# The coefficients\n",
        "print ('Coefficients: ', regr.coef_)\n",
        "print ('Intercept: ',regr.intercept_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msrQT7Csyt2E"
      },
      "source": [
        "In linear regression, the coefficients represent the weights assigned to each feature, and the intercept is the value of the predicted response when all independent variables are zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "9CGy_pqRxOwP",
        "outputId": "712dc627-2714-4106-b748-83f6397621d6"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_x, regr.coef_ * train_x + regr.intercept_, '-r')\n",
        "plt.xlabel(\"Inflight entertainment\")\n",
        "plt.ylabel(\"satisfaction\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEpvPI760kI5"
      },
      "source": [
        "####Evaluation Linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qNPBBLekadV",
        "outputId": "b63264cd-b772-41f2-df71-070144f39c87"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "test_x = np.asanyarray(X_test[['Inflight entertainment']])\n",
        "test_y = np.asanyarray(y_test)\n",
        "test_y_ = regr.predict(test_x)\n",
        "\n",
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\n",
        "print(\"R2-score: %.2f\" % r2_score(test_y , test_y_) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU62_HUF2kfC"
      },
      "source": [
        "\n",
        "\n",
        "* **Interpretation:**\n",
        "\n",
        " The MAE and MSE provide insights into the magnitude of errors, with lower values indicating better performance.\n",
        "The R2-score gives an idea of the proportion of variability explained by  model. An R2-score of 0.27 suggests that there may be room for improvement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dmn2FjI5zO_"
      },
      "source": [
        "Seat comfort & Food and drink"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkoIlmUOkaf_",
        "outputId": "0d84d3aa-ff9a-49d4-ab42-bf990d3d151a"
      },
      "outputs": [],
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "train_x = np.asanyarray(X_train[['Seat comfort']])\n",
        "train_y = np.asanyarray(X_train[['Food and drink']])\n",
        "regr.fit (train_x, train_y)\n",
        "\n",
        "# The coefficients\n",
        "print ('Coefficients: ', regr.coef_)\n",
        "print ('Intercept: ',regr.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "YFqtlIGokaiq",
        "outputId": "3a059b7a-1dd3-4fc8-f247-45108157c9ef"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_x, regr.coef_ * train_x + regr.intercept_, '-r')\n",
        "plt.xlabel(\"Seat comfort\")\n",
        "plt.ylabel(\"Food and drink\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtZMekqEkalW",
        "outputId": "eb0a6a47-578c-4d0a-d7bc-9d92cf0b01c4"
      },
      "outputs": [],
      "source": [
        "test_x = np.asanyarray(X_test[['Seat comfort']])\n",
        "test_y = np.asanyarray(X_test[['Food and drink']])\n",
        "test_y_ = regr.predict(test_x)\n",
        "\n",
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\n",
        "print(\"R2-score: %.2f\" % r2_score(test_y , test_y_) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uelwdYvm5rEQ"
      },
      "source": [
        "Online boarding & Inflight wifi service"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCAuZhU1kaoE",
        "outputId": "6d037739-34e3-4f32-a3b4-eb39ef5dbe5d"
      },
      "outputs": [],
      "source": [
        "regr = linear_model.LinearRegression()\n",
        "train_x = np.asanyarray(X_train[['Online boarding']])\n",
        "train_y = np.asanyarray(X_train[['Inflight wifi service']])\n",
        "regr.fit (train_x, train_y)\n",
        "\n",
        "# The coefficients\n",
        "print ('Coefficients: ', regr.coef_)\n",
        "print ('Intercept: ',regr.intercept_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "MdEKmgO75FWX",
        "outputId": "9a37d2e2-06b9-41c0-e104-83a0299e6905"
      },
      "outputs": [],
      "source": [
        "plt.plot(train_x, regr.coef_ * train_x + regr.intercept_, '-r')\n",
        "plt.xlabel(\"Online boarding\")\n",
        "plt.ylabel(\"Inflight wifi service\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL3sceCr5Fbb",
        "outputId": "97358542-09b0-42bd-f712-0107b664c8a9"
      },
      "outputs": [],
      "source": [
        "test_x = np.asanyarray(X_test[['Online boarding']])\n",
        "test_y = np.asanyarray(X_test[['Inflight wifi service']])\n",
        "test_y_ = regr.predict(test_x)\n",
        "\n",
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\n",
        "print(\"R2-score: %.2f\" % r2_score(test_y , test_y_) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYtYQUzEH4_9"
      },
      "source": [
        "##REGRESSION (Total_Score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiKnmdceO06f"
      },
      "source": [
        "\n",
        "\n",
        " **5 common regression models:**\n",
        " 1. Linear Regression\n",
        " 2. Decision Tree Regressor\n",
        " 3. Random Forest Regressor\n",
        " 4. Support Vector Regressor (SVR) --  high run time!!! --\n",
        " 5. Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5C7fIIwOsPu"
      },
      "source": [
        "Bayesian Ridge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "voBt3avbKC3V"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold, GridSearchCV, cross_val_predict\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  dfc is  DataFrame with features and target variable\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "mape_scores = []\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "mse_scores = []\n",
        "mspe_scores = []\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'alpha_1': [1e-6, 1e-4, 1e-2, 1e-1, 1, 10, 100],\n",
        "    'alpha_2': [1e-6, 1e-4, 1e-2, 1e-1, 1, 10, 100],\n",
        "    'lambda_1': [1e-6, 1e-4, 1e-2, 1e-1, 1, 10, 100],\n",
        "    'lambda_2': [1e-6, 1e-4, 1e-2, 1e-1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Perform hyperparameter tuning with GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=BayesianRidge(), param_grid=param_grid, scoring='neg_mean_squared_error', cv=k_folds)\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_hyperparameters = grid_search.best_params_\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model on the training set\n",
        "    bayesian_ridge_model = BayesianRidge(**best_hyperparameters)\n",
        "    bayesian_ridge_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = bayesian_ridge_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for the fold\n",
        "    fold_mape = np.mean(np.abs((y_val_fold - y_val_pred) / y_val_fold)) * 100\n",
        "    fold_mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "    fold_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Calculate MSPE\n",
        "    fold_mspe = np.mean(((y_val_fold - y_val_pred) / y_val_fold) ** 2) * 100\n",
        "\n",
        "    mape_scores.append(fold_mape)\n",
        "    mae_scores.append(fold_mae)\n",
        "    r2_scores.append(fold_r2)\n",
        "    mse_scores.append(fold_mse)\n",
        "    mspe_scores.append(fold_mspe)\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_mape = np.mean(mape_scores)\n",
        "mean_mae = np.mean(mae_scores)\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "mean_mspe = np.mean(mspe_scores)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best Hyperparameters: {best_hyperparameters}\")\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Mean Squared Error: {mean_mse:.4f}\")\n",
        "print(f\"Standard Deviation of Mean Squared Error: {std_mse:.4f}\")\n",
        "print(f\"R-squared (R2) Score: {mean_r2:.4f}\")\n",
        "print(f\"Mean Absolute Error: {mean_mae:.4f}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mean_mape:.4f}%\")\n",
        "print(f\"Mean Squared Percentage Error (MSPE): {mean_mspe:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = cross_val_predict(bayesian_ridge_model, X, y, cv=k_folds)\n",
        "plt.scatter(y, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Bayesian Ridge Regression - Predicted vs. Actual Values\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL71xa5nuGtE"
      },
      "source": [
        "Elastic Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEaOVnhEuG5C",
        "outputId": "07fa9dfc-a4b2-4bbf-e320-040f54ea05d1"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Elastic Net regression model\n",
        "elastic_net_model = ElasticNet()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'alpha': [0.1, 1, 10, 100],\n",
        "    'l1_ratio': [0.1, 0.5, 0.7, 0.9]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=elastic_net_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_alpha = grid_search.best_params_['alpha']\n",
        "best_l1_ratio = grid_search.best_params_['l1_ratio']\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "mape_scores = []\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "mse_scores = []\n",
        "mspe_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model on the validation set\n",
        "    final_model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for the fold\n",
        "    fold_mape = np.mean(np.abs((y_val_fold - y_val_pred) / y_val_fold)) * 100\n",
        "    fold_mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "    fold_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Calculate MSPE\n",
        "    fold_mspe = np.mean(((y_val_fold - y_val_pred) / y_val_fold) ** 2) * 100\n",
        "\n",
        "    mape_scores.append(fold_mape)\n",
        "    mae_scores.append(fold_mae)\n",
        "    r2_scores.append(fold_r2)\n",
        "    mse_scores.append(fold_mse)\n",
        "    mspe_scores.append(fold_mspe)\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_mape = np.mean(mape_scores)\n",
        "mean_mae = np.mean(mae_scores)\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "mean_mspe = np.mean(mspe_scores)\n",
        "\n",
        "# Print the best hyperparameters and evaluation metrics\n",
        "print(f\"Best alpha: {best_alpha}\")\n",
        "print(f\"Best l1_ratio: {best_l1_ratio}\")\n",
        "print(f\"Mean Squared Error: {mean_mse:.4f}\")\n",
        "print(f\"Standard Deviation of Mean Squared Error: {std_mse:.4f}\")\n",
        "print(f\"R-squared (R2) Score: {mean_r2:.4f}\")\n",
        "print(f\"Mean Absolute Error: {mean_mae:.4f}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mean_mape:.4f}%\")\n",
        "print(f\"Mean Squared Percentage Error (MSPE): {mean_mspe:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI3MWigxyyuD",
        "outputId": "9c0b2b05-207f-4ea5-e237-586231e4d26f"
      },
      "outputs": [],
      "source": [
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = final_model.predict(X_test)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Elastic Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEC58NMDwzOv"
      },
      "source": [
        "KNeighbors Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DtE2ll7mwzWa",
        "outputId": "4dc0a60d-b88e-4ecd-9a52-fb7b5f7c93ab"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the KNN Regressor model\n",
        "knn_model = KNeighborsRegressor()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]\n",
        "}\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=k_folds)\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "mae_scores = []\n",
        "r2_scores = []\n",
        "mse_scores = []\n",
        "mape_scores = []\n",
        "mspe_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Fit the model to the training data\n",
        "    grid_search.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = grid_search.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for the fold\n",
        "    fold_mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "    fold_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Calculate MSPE\n",
        "    fold_mspe = np.mean(((y_val_fold - y_val_pred) / y_val_fold) ** 2) * 100\n",
        "\n",
        "    # Calculate MAPE\n",
        "    fold_mape = np.mean(np.abs((y_val_fold - y_val_pred) / y_val_fold)) * 100\n",
        "\n",
        "    mae_scores.append(fold_mae)\n",
        "    r2_scores.append(fold_r2)\n",
        "    mse_scores.append(fold_mse)\n",
        "    mspe_scores.append(fold_mspe)\n",
        "    mape_scores.append(fold_mape)\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_mae = np.mean(mae_scores)\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "mean_mspe = np.mean(mspe_scores)\n",
        "mean_mape = np.mean(mape_scores)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f\"Mean Squared Error: {mean_mse:.4f}\")\n",
        "print(f\"Standard Deviation of Mean Squared Error: {std_mse:.4f}\")\n",
        "print(f\"R-squared (R2) Score: {mean_r2:.4f}\")\n",
        "print(f\"Mean Absolute Error: {mean_mae:.4f}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mean_mape:.4f}%\")\n",
        "print(f\"Mean Squared Percentage Error (MSPE): {mean_mspe:.4f}\")\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpGhSoz3yeq8",
        "outputId": "ce4267a8-681d-451f-cfd2-5811241a7452"
      },
      "outputs": [],
      "source": [
        "# Plot predicted vs. actual values for better visualization\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"KNeighbors Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcVy8CMhQD2l"
      },
      "source": [
        "Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTPN7YQFyeXk",
        "outputId": "7e125caa-bc01-4d78-f07e-ec0968484c49"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Decision Tree Regressor model\n",
        "dt_regressor = DecisionTreeRegressor()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=dt_regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_max_depth = best_params['max_depth']\n",
        "best_min_samples_split = best_params['min_samples_split']\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store metrics for each fold\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "mae_scores = []\n",
        "mape_scores = []\n",
        "mspe_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Initialize Decision Tree Regressor with the best hyperparameters\n",
        "    final_model = DecisionTreeRegressor(max_depth=best_max_depth, min_samples_split=best_min_samples_split)\n",
        "\n",
        "    # Fit the model to the training fold\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for the fold\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "    fold_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "    fold_mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "    fold_mape = mean_absolute_percentage_error(y_val_fold, y_val_pred)\n",
        "    fold_mspe = (fold_mape / 100) ** 2  # Calculating MSPE from MAPE\n",
        "\n",
        "    mse_scores.append(fold_mse)\n",
        "    r2_scores.append(fold_r2)\n",
        "    mae_scores.append(fold_mae)\n",
        "    mape_scores.append(fold_mape)\n",
        "    mspe_scores.append(fold_mspe)\n",
        "\n",
        "# Calculate mean and standard deviation of metrics\n",
        "mean_mse = pd.Series(mse_scores).mean()\n",
        "std_mse = pd.Series(mse_scores).std()\n",
        "mean_r2 = pd.Series(r2_scores).mean()\n",
        "mean_mae = pd.Series(mae_scores).mean()\n",
        "mean_mape = pd.Series(mape_scores).mean()\n",
        "mean_mspe = pd.Series(mspe_scores).mean()\n",
        "\n",
        "# Print the best hyperparameters and evaluation metrics\n",
        "print(f\"Best Max Depth: {best_max_depth}\")\n",
        "print(f\"Best Min Samples Split: {best_min_samples_split}\")\n",
        "print(f\"Mean Squared Error: {mean_mse:.4f}\")\n",
        "print(f\"Standard Deviation of Mean Squared Error: {std_mse:.4f}\")\n",
        "print(f\"R-squared (R2) Score: {mean_r2:.4f}\")\n",
        "print(f\"Mean Absolute Error: {mean_mae:.4f}\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mean_mape:.4f}%\")\n",
        "print(f\"Mean Squared Percentage Error (MSPE): {mean_mspe:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = grid_search.predict(X_test)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Decision Tree Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "mKE-l8P3OJwS",
        "outputId": "44f5226a-2ed2-42d2-aa65-f3b71d7bc336"
      },
      "outputs": [],
      "source": [
        "plt.scatter(y_test, y_pred)\n",
        "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], linestyle='--', color='red', linewidth=2)  # Line of unity\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Decision Tree Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCNc7Pp-SFm-"
      },
      "source": [
        "Random Forest Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwnQtObZyXlK",
        "outputId": "d1720fa1-afb7-460a-d2ce-91ec7be6b604"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Random Forest Regressor model\n",
        "rf_regressor = RandomForestRegressor()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=rf_regressor, param_distributions=param_dist, n_iter=10, scoring='neg_mean_squared_error', cv=5, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store metrics for each fold\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "mae_scores = []\n",
        "mape_scores = []\n",
        "mspe_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = RandomForestRegressor(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for the fold\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "    fold_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "    fold_mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    fold_mape = np.mean(np.abs((y_val_fold - y_val_pred) / y_val_fold)) * 100\n",
        "\n",
        "    # Calculate MSPE\n",
        "    fold_mspe = np.mean(((y_val_fold - y_val_pred) / y_val_fold) ** 2) * 100\n",
        "\n",
        "    mse_scores.append(fold_mse)\n",
        "    r2_scores.append(fold_r2)\n",
        "    mae_scores.append(fold_mae)\n",
        "    mape_scores.append(fold_mape)\n",
        "    mspe_scores.append(fold_mspe)\n",
        "\n",
        "# Calculate mean and standard deviation of metrics\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "std_r2 = np.std(r2_scores)\n",
        "\n",
        "mean_mae = np.mean(mae_scores)\n",
        "std_mae = np.std(mae_scores)\n",
        "\n",
        "mean_mape = np.mean(mape_scores)\n",
        "mean_mspe = np.mean(mspe_scores)\n",
        "\n",
        "# Print the best hyperparameters and evaluation metrics\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n",
        "print(f\"Mean Squared Error: {mean_mse:.4f} (±{std_mse:.4f})\")\n",
        "print(f\"R-squared: {mean_r2:.4f} (±{std_r2:.4f})\")\n",
        "print(f\"Mean Absolute Error: {mean_mae:.4f} (±{std_mae:.4f})\")\n",
        "print(f\"Mean Absolute Percentage Error (MAPE): {mean_mape:.4f}%\")\n",
        "print(f\"Mean Squared Percentage Error (MSPE): {mean_mspe:.4f}%\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = final_model.predict(X_test)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\"Random Forest Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RBAgyU5vMWV"
      },
      "source": [
        "SVR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jONN776IvMhp",
        "outputId": "fc23645d-912f-4ac7-b9b1-b2c90292af3a"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Support Vector Regression model\n",
        "svr_model = SVR()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'C': np.logspace(-3, 3, 7),\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto'] + list(np.logspace(-3, 3, 7))\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    svr_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    cv=5,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    verbose=1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store mean squared error for each fold\n",
        "mse_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = SVR(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate mean squared error for the fold\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "    mse_scores.append(fold_mse)\n",
        "\n",
        "# Calculate mean and standard deviation of mean squared error scores\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "# Print the best hyperparameters and evaluation metrics\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Squared Error: {mean_mse:.4f}')\n",
        "print(f'Standard Deviation of Mean Squared Error: {std_mse:.4f}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire train\n",
        "final_model = SVR(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error on Test Set: {mse:.4f}')\n",
        "print(f'R-squared Score on Test Set: {r2:.4f}')\n",
        "print(f'Mean Absolute Error on Test Set: {mae:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiSR6XRr58fC"
      },
      "outputs": [],
      "source": [
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = final_model.predict(X_test)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\" Gradient Boosting Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZhMYFahvTif"
      },
      "source": [
        "2 Sampling Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8h8rLAnvTzF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def simple_random_sampling(data, sample_size):\n",
        "    # Randomly sample from the entire dataset\n",
        "    random_sample = data.sample(sample_size, random_state=42)  # Setting a random state for reproducibility\n",
        "    return random_sample\n",
        "\n",
        "def stratified_random_sampling(data, strata_col, sample_size):\n",
        "    # Create an empty DataFrame to store the sampled data\n",
        "    sampled_data = pd.DataFrame()\n",
        "\n",
        "    # Identify unique strata in the dataset\n",
        "    strata_values = data[strata_col].unique()\n",
        "\n",
        "    # Perform stratified random sampling for each stratum\n",
        "    for stratum in strata_values:\n",
        "        # Select data points belonging to the current stratum\n",
        "        stratum_data = data[data[strata_col] == stratum]\n",
        "\n",
        "        # Determine the number of samples to draw from the stratum\n",
        "        stratum_sample_size = int(sample_size * len(stratum_data) / len(data))\n",
        "\n",
        "        # Randomly sample from the current stratum\n",
        "        stratum_sample = stratum_data.sample(stratum_sample_size, random_state=42)  # Setting a random state for reproducibility\n",
        "\n",
        "        # Append the stratum sample to the overall sampled data\n",
        "        sampled_data = pd.concat([sampled_data, stratum_sample])\n",
        "\n",
        "    return sampled_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kMEIL-fWcoQ"
      },
      "source": [
        "Gradient Boosting Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmBn0vB9Wc1L",
        "outputId": "364073d3-d140-4001-8287-8c6ad110c0c7"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting Regressor model\n",
        "gb_model = GradientBoostingRegressor()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(gb_model, param_distributions=param_dist, n_iter=20, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store mean squared error for each fold\n",
        "mse_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = GradientBoostingRegressor(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate mean squared error for the fold\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "    mse_scores.append(fold_mse)\n",
        "\n",
        "# Calculate mean and standard deviation of mean squared error scores\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Squared Error: {mean_mse:.4f}')\n",
        "print(f'Standard Deviation of Mean Squared Error: {std_mse:.4f}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = GradientBoostingRegressor(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error on Test Set: {mse:.4f}')\n",
        "print(f'R-squared Score on Test Set: {r2:.4f}')\n",
        "print(f'Mean Absolute Error on Test Set: {mae:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jna-bzglyQFy",
        "outputId": "76f82196-bc97-4632-de58-3b8c71ab9550"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import numpy as np\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting Regressor model\n",
        "gb_model = GradientBoostingRegressor()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(gb_model, param_distributions=param_dist, n_iter=20, cv=5, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize arrays to store evaluation metrics for each fold\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "mae_scores = []\n",
        "mape_scores = []\n",
        "mspe_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = GradientBoostingRegressor(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for the fold\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "    fold_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "    fold_mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    fold_mape = np.mean(np.abs((y_val_fold - y_val_pred) / y_val_fold)) * 100\n",
        "\n",
        "    # Calculate MSPE\n",
        "    fold_mspe = np.mean(((y_val_fold - y_val_pred) / y_val_fold) ** 2) * 100\n",
        "\n",
        "    mse_scores.append(fold_mse)\n",
        "    r2_scores.append(fold_r2)\n",
        "    mae_scores.append(fold_mae)\n",
        "    mape_scores.append(fold_mape)\n",
        "    mspe_scores.append(fold_mspe)\n",
        "\n",
        "# Calculate mean and standard deviation of metrics\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "std_r2 = np.std(r2_scores)\n",
        "\n",
        "mean_mae = np.mean(mae_scores)\n",
        "std_mae = np.std(mae_scores)\n",
        "\n",
        "mean_mape = np.mean(mape_scores)\n",
        "mean_mspe = np.mean(mspe_scores)\n",
        "\n",
        "# Print the best hyperparameters and evaluation metrics\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Squared Error: {mean_mse:.4f} (±{std_mse:.4f})')\n",
        "print(f'R-squared: {mean_r2:.4f} (±{std_r2:.4f})')\n",
        "print(f'Mean Absolute Error: {mean_mae:.4f} (±{std_mae:.4f})')\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mean_mape:.4f}%')\n",
        "print(f'Mean Squared Percentage Error (MSPE): {mean_mspe:.4f}%')\n",
        "print(\"\\n\")\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = GradientBoostingRegressor(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error on Test Set: {mse:.4f}')\n",
        "print(f'R-squared Score on Test Set: {r2:.4f}')\n",
        "print(f'Mean Absolute Error on Test Set: {mae:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPX6olz_58fE",
        "outputId": "bfbae73a-0e88-4dc1-9b48-7779212f1929"
      },
      "outputs": [],
      "source": [
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = final_model.predict(X_test)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\" Gradient Boosting Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOCGOU-E58fE"
      },
      "source": [
        "poission reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WjeDP0kxyE-s",
        "outputId": "c1f3bcb4-875a-4174-fd25-1be6a2766682"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.linear_model import PoissonRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "X = df1.drop('Total_Score', axis=1)\n",
        "y = df1['Total_Score']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid for grid search\n",
        "param_grid = {\n",
        "    'alpha': [0.01, 0.1, 1.0, 10.0],\n",
        "    'tol': [1e-4, 1e-3, 1e-2]\n",
        "}\n",
        "\n",
        "# Initialize Poisson Regressor\n",
        "poisson_regressor = PoissonRegressor()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(poisson_regressor, param_grid, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Use k-fold cross-validation for final evaluation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store evaluation metrics for each fold\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_scores = []\n",
        "mape_scores = []\n",
        "mspe_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model on the validation set\n",
        "    final_model = PoissonRegressor(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate evaluation metrics for the fold\n",
        "    fold_mae = mean_absolute_error(y_val_fold, y_val_pred)\n",
        "    fold_mse = mean_squared_error(y_val_fold, y_val_pred)\n",
        "    fold_r2 = r2_score(y_val_fold, y_val_pred)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    fold_mape = np.mean(np.abs((y_val_fold - y_val_pred) / y_val_fold)) * 100\n",
        "\n",
        "    # Calculate MSPE\n",
        "    fold_mspe = np.mean(((y_val_fold - y_val_pred) / y_val_fold) ** 2) * 100\n",
        "\n",
        "    mae_scores.append(fold_mae)\n",
        "    mse_scores.append(fold_mse)\n",
        "    r2_scores.append(fold_r2)\n",
        "    mape_scores.append(fold_mape)\n",
        "    mspe_scores.append(fold_mspe)\n",
        "\n",
        "    print(f'Mean Absolute Error for Fold {fold + 1}: {fold_mae}')\n",
        "    print(f'Mean Squared Error for Fold {fold + 1}: {fold_mse}')\n",
        "    print(f'R-squared for Fold {fold + 1}: {fold_r2}')\n",
        "    print(f'MAPE for Fold {fold + 1}: {fold_mape}%')\n",
        "    print(f'MSPE for Fold {fold + 1}: {fold_mspe}%')\n",
        "\n",
        "# Calculate mean and standard deviation of evaluation metrics\n",
        "mean_mae = np.mean(mae_scores)\n",
        "std_mae = np.std(mae_scores)\n",
        "mean_mse = np.mean(mse_scores)\n",
        "std_mse = np.std(mse_scores)\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "std_r2 = np.std(r2_scores)\n",
        "mean_mape = np.mean(mape_scores)\n",
        "mean_mspe = np.mean(mspe_scores)\n",
        "\n",
        "print(f'Mean Mean Absolute Error: {mean_mae}')\n",
        "print(f'Standard Deviation of Mean Absolute Error: {std_mae}')\n",
        "print(f'Mean Mean Squared Error: {mean_mse}')\n",
        "print(f'Standard Deviation of Mean Squared Error: {std_mse}')\n",
        "print(f'Mean R-squared: {mean_r2}')\n",
        "print(f'Standard Deviation of R-squared: {std_r2}')\n",
        "print(f'Mean MAPE: {mean_mape}%')\n",
        "print(f'Mean MSPE: {mean_mspe}%')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = PoissonRegressor(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_mae = mean_absolute_error(y_test, y_pred)\n",
        "test_mse = mean_squared_error(y_test, y_pred)\n",
        "test_r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Calculate MAPE for the test set\n",
        "test_mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "# Calculate MSPE for the test set\n",
        "test_mspe = np.mean(((y_test - y_pred) / y_test) ** 2) * 100\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Absolute Error on Test Set: {test_mae}')\n",
        "print(f'Mean Squared Error on Test Set: {test_mse}')\n",
        "print(f'R-squared on Test Set: {test_r2}')\n",
        "print(f'MAPE on Test Set: {test_mape}%')\n",
        "print(f'MSPE on Test Set: {test_mspe}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6skGU_Y58fF",
        "outputId": "c00491b9-7544-41ac-ad20-3a519a6893b4"
      },
      "outputs": [],
      "source": [
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = final_model.predict(X_test)\n",
        "plt.scatter(y_test, y_pred)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\" poission Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Nn9UZKp58fF"
      },
      "source": [
        "MLPREg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1cLRqFzt58fF",
        "outputId": "99673730-e26f-4fbe-91aa-204f1c1b7ccf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- MLP Regressor ---\n",
        "\n",
        "# Define the hyperparameter grid for randomized search\n",
        "param_dist_mlp = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
        "    'activation': ['logistic', 'tanh', 'relu'],\n",
        "    'alpha': np.logspace(-4, 0, 5),\n",
        "}\n",
        "\n",
        "# Initialize MLP Regressor\n",
        "mlp_regressor = MLPRegressor(max_iter=1000, random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search_mlp = RandomizedSearchCV(mlp_regressor, param_distributions=param_dist_mlp, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "random_search_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters for MLP Regressor\n",
        "best_params_mlp = random_search_mlp.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation for MLP Regressor\n",
        "k_folds_mlp = 10\n",
        "kf_mlp = KFold(n_splits=k_folds_mlp, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store regression metrics for each fold\n",
        "mse_scores_mlp = []\n",
        "mae_scores_mlp = []\n",
        "r2_scores_mlp = []\n",
        "\n",
        "# Perform k-fold cross-validation for MLP Regressor\n",
        "for fold, (train_index, val_index) in enumerate(kf_mlp.split(X_train)):\n",
        "    X_train_fold_mlp, X_val_fold_mlp = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold_mlp, y_val_fold_mlp = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Initialize MLP Regressor with the best hyperparameters\n",
        "    final_model_mlp = MLPRegressor(max_iter=1000, random_state=42, **best_params_mlp)\n",
        "\n",
        "    # Fit the model to the training fold\n",
        "    final_model_mlp.fit(X_train_fold_mlp, y_train_fold_mlp)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    y_val_pred_mlp = final_model_mlp.predict(X_val_fold_mlp)\n",
        "\n",
        "    # Calculate regression metrics for the fold\n",
        "    fold_mse_mlp = mean_squared_error(y_val_fold_mlp, y_val_pred_mlp)\n",
        "    fold_mae_mlp = mean_absolute_error(y_val_fold_mlp, y_val_pred_mlp)\n",
        "    fold_r2_mlp = r2_score(y_val_fold_mlp, y_val_pred_mlp)\n",
        "\n",
        "    mse_scores_mlp.append(fold_mse_mlp)\n",
        "    mae_scores_mlp.append(fold_mae_mlp)\n",
        "    r2_scores_mlp.append(fold_r2_mlp)\n",
        "\n",
        "# Calculate mean and standard deviation of regression metrics for MLP Regressor\n",
        "mean_mse_mlp = pd.Series(mse_scores_mlp).mean()\n",
        "std_mse_mlp = pd.Series(mse_scores_mlp).std()\n",
        "\n",
        "mean_mae_mlp = pd.Series(mae_scores_mlp).mean()\n",
        "std_mae_mlp = pd.Series(mae_scores_mlp).std()\n",
        "\n",
        "mean_r2_mlp = pd.Series(r2_scores_mlp).mean()\n",
        "std_r2_mlp = pd.Series(r2_scores_mlp).std()\n",
        "\n",
        "print(f'Best Hyperparameters (MLP Regressor): {best_params_mlp}')\n",
        "print(f'Mean Squared Error (MLP Regressor): {mean_mse_mlp:.4f} ± {std_mse_mlp:.4f}')\n",
        "print(f'Mean Absolute Error (MLP Regressor): {mean_mae_mlp:.4f} ± {std_mae_mlp:.4f}')\n",
        "print(f'R-squared (MLP Regressor): {mean_r2_mlp:.4f} ± {std_r2_mlp:.4f}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set for MLP Regressor\n",
        "final_model_mlp = MLPRegressor(max_iter=1000, random_state=42, **best_params_mlp)\n",
        "final_model_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set for MLP Regressor\n",
        "y_pred_mlp = final_model_mlp.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P82g6hByBcy",
        "outputId": "1b7d8f43-61e8-4695-94f4-5bab0009d1ae"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X = df.drop('Total_Score', axis=1)\n",
        "y = df['Total_Score']\n",
        "\n",
        "#  X and y are features and target variable\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- MLP Regressor ---\n",
        "\n",
        "# Define the hyperparameter grid for randomized search\n",
        "param_dist_mlp = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
        "    'activation': ['logistic', 'tanh', 'relu'],\n",
        "    'alpha': np.logspace(-4, 0, 5),\n",
        "}\n",
        "\n",
        "# Initialize MLP Regressor\n",
        "mlp_regressor = MLPRegressor(max_iter=1000, random_state=42)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search_mlp = RandomizedSearchCV(mlp_regressor, param_distributions=param_dist_mlp, n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "random_search_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters for MLP Regressor\n",
        "best_params_mlp = random_search_mlp.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation for MLP Regressor\n",
        "k_folds_mlp = 10\n",
        "kf_mlp = KFold(n_splits=k_folds_mlp, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store regression metrics for each fold\n",
        "mse_scores_mlp = []\n",
        "mae_scores_mlp = []\n",
        "r2_scores_mlp = []\n",
        "mape_scores_mlp = []\n",
        "mspe_scores_mlp = []\n",
        "\n",
        "# Perform k-fold cross-validation for MLP Regressor\n",
        "for fold, (train_index, val_index) in enumerate(kf_mlp.split(X_train)):\n",
        "    X_train_fold_mlp, X_val_fold_mlp = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold_mlp, y_val_fold_mlp = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Initialize MLP Regressor with the best hyperparameters\n",
        "    final_model_mlp = MLPRegressor(max_iter=1000, random_state=42, **best_params_mlp)\n",
        "\n",
        "    # Fit the model to the training fold\n",
        "    final_model_mlp.fit(X_train_fold_mlp, y_train_fold_mlp)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    y_val_pred_mlp = final_model_mlp.predict(X_val_fold_mlp)\n",
        "\n",
        "    # Calculate regression metrics for the fold\n",
        "    fold_mse_mlp = mean_squared_error(y_val_fold_mlp, y_val_pred_mlp)\n",
        "    fold_mae_mlp = mean_absolute_error(y_val_fold_mlp, y_val_pred_mlp)\n",
        "    fold_r2_mlp = r2_score(y_val_fold_mlp, y_val_pred_mlp)\n",
        "\n",
        "    # Calculate MAPE\n",
        "    fold_mape_mlp = np.mean(np.abs((y_val_fold_mlp - y_val_pred_mlp) / y_val_fold_mlp)) * 100\n",
        "\n",
        "    # Calculate MSPE\n",
        "    fold_mspe_mlp = np.mean(((y_val_fold_mlp - y_val_pred_mlp) / y_val_fold_mlp) ** 2) * 100\n",
        "\n",
        "    mse_scores_mlp.append(fold_mse_mlp)\n",
        "    mae_scores_mlp.append(fold_mae_mlp)\n",
        "    r2_scores_mlp.append(fold_r2_mlp)\n",
        "    mape_scores_mlp.append(fold_mape_mlp)\n",
        "    mspe_scores_mlp.append(fold_mspe_mlp)\n",
        "\n",
        "    print(f'Mean Squared Error for Fold {fold + 1}: {fold_mse_mlp}')\n",
        "    print(f'Mean Absolute Error for Fold {fold + 1}: {fold_mae_mlp}')\n",
        "    print(f'R-squared for Fold {fold + 1}: {fold_r2_mlp}')\n",
        "    print(f'MAPE for Fold {fold + 1}: {fold_mape_mlp}%')\n",
        "    print(f'MSPE for Fold {fold + 1}: {fold_mspe_mlp}%')\n",
        "\n",
        "# Calculate mean and standard deviation of regression metrics for MLP Regressor\n",
        "mean_mse_mlp = pd.Series(mse_scores_mlp).mean()\n",
        "std_mse_mlp = pd.Series(mse_scores_mlp).std()\n",
        "\n",
        "mean_mae_mlp = pd.Series(mae_scores_mlp).mean()\n",
        "std_mae_mlp = pd.Series(mae_scores_mlp).std()\n",
        "\n",
        "mean_r2_mlp = pd.Series(r2_scores_mlp).mean()\n",
        "std_r2_mlp = pd.Series(r2_scores_mlp).std()\n",
        "\n",
        "mean_mape_mlp = pd.Series(mape_scores_mlp).mean()\n",
        "mean_mspe_mlp = pd.Series(mspe_scores_mlp).mean()\n",
        "\n",
        "print(f'Best Hyperparameters (MLP Regressor): {best_params_mlp}')\n",
        "print(f'Mean Squared Error (MLP Regressor): {mean_mse_mlp:.4f} ± {std_mse_mlp:.4f}')\n",
        "print(f'Mean Absolute Error (MLP Regressor): {mean_mae_mlp:.4f} ± {std_mae_mlp:.4f}')\n",
        "print(f'R-squared (MLP Regressor): {mean_r2_mlp:.4f} ± {std_r2_mlp:.4f}')\n",
        "print(f'MAPE (MLP Regressor): {mean_mape_mlp:.4f}%')\n",
        "print(f'MSPE (MLP Regressor): {mean_mspe_mlp:.4f}%')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set for MLP Regressor\n",
        "final_model_mlp = MLPRegressor(max_iter=1000, random_state=42, **best_params_mlp)\n",
        "final_model_mlp.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set for MLP Regressor\n",
        "y_pred_mlp = final_model_mlp.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set for MLP Regressor\n",
        "test_mse_mlp = mean_squared_error(y_test, y_pred_mlp)\n",
        "test_mae_mlp = mean_absolute_error(y_test, y_pred_mlp)\n",
        "test_r2_mlp = r2_score(y_test, y_pred_mlp)\n",
        "\n",
        "# Calculate MAPE for the test set for MLP Regressor\n",
        "test_mape_mlp = np.mean(np.abs((y_test - y_pred_mlp) / y_test)) * 100\n",
        "\n",
        "# Calculate MSPE for the test set for MLP Regressor\n",
        "test_mspe_mlp = np.mean(((y_test - y_pred_mlp) / y_test) ** 2) * 100\n",
        "\n",
        "print(f'Best Hyperparameters (MLP Regressor): {best_params_mlp}')\n",
        "print(f'Mean Squared Error on Test Set (MLP Regressor): {test_mse_mlp:.4f}')\n",
        "print(f'Mean Absolute Error on Test Set (MLP Regressor): {test_mae_mlp:.4f}')\n",
        "print(f'R-squared on Test Set (MLP Regressor): {test_r2_mlp:.4f}')\n",
        "print(f'MAPE on Test Set (MLP Regressor): {test_mape_mlp:.4f}%')\n",
        "print(f'MSPE on Test Set (MLP Regressor): {test_mspe_mlp:.4f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6X79QP5g58fG",
        "outputId": "38cdf3d2-b45d-4255-9445-ccf3d0c51f59"
      },
      "outputs": [],
      "source": [
        "# Optional: Plot predicted vs. actual values for better visualization\n",
        "y_pred = final_model.predict(X_test)\n",
        "plt.scatter(y_test, y_pred_mlp)\n",
        "plt.xlabel(\"Actual Values\")\n",
        "plt.ylabel(\"Predicted Values\")\n",
        "plt.title(\" poission Regressor - Predicted vs. Actual Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlJaWPOzJ-fF"
      },
      "source": [
        "## Classification(satisfaction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXbdbHCrDbAx"
      },
      "source": [
        "###Naive Bayes\n",
        "####GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QXeH6xDVzYj",
        "outputId": "dd788671-fc68-4582-c835-28574b664264"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Separate features and target variable\n",
        "X = df1.drop('satisfaction', axis=1)\n",
        "y = df1['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Gaussian Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the model on the training data\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UfnKFizz956",
        "outputId": "48e4aed7-f0b5-4264-a444-a5170c2d8a76"
      },
      "outputs": [],
      "source": [
        "# Separate features and target variable\n",
        "X = dfc.drop('satisfaction', axis=1)\n",
        "y = dfc['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Gaussian Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the model on the training data\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Accuracy: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfiIb7eL58fH",
        "outputId": "84fbf791-7abd-4f95-c8ce-53895b3e8c4e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Given confusion matrix\n",
        "conf_matrix = np.array([[11493, 2676], [2496, 11688]])\n",
        "\n",
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "# Calculate Sensitivity (True Positive Rate or Recall for the positive class)\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "\n",
        "# Calculate Specificity (True Negative Rate)\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "DBsIift8Gufs",
        "outputId": "acfdfd24-09a3-44ac-f02f-e95b666fced6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred_proba = nb_classifier.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mznFQc6Knqt"
      },
      "source": [
        "KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNDdiSp0LGcz"
      },
      "outputs": [],
      "source": [
        "#scalling process specified for df1\n",
        "c = df1.columns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "Scaler = MinMaxScaler()\n",
        "df1 = Scaler.fit_transform(df1)\n",
        "\n",
        "df1 = pd.DataFrame(df1)\n",
        "\n",
        "df1.columns = c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eLSEGDpDXnr",
        "outputId": "67cdad1b-848d-4255-8551-a5330628ce61"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X = df1.drop('satisfaction', axis=1)\n",
        "y = df1['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the KNN model\n",
        "knn_model = KNeighborsClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],  \n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'p': [1, 2]  # 1 for Manhattan distance, 2 for Euclidean distance\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=knn_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = KNeighborsClassifier(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Accuracy: {mean_accuracy}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = KNeighborsClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i06P_tbpZ63D"
      },
      "source": [
        "Best Hyperparameters: {'n_neighbors': 7, 'p': 1, 'weights': 'distance'}\n",
        "\n",
        "Accuracy: 0.9332380878832343\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[11104   717]\n",
        "\n",
        " [ 1012 13065]]\n",
        "\n",
        "Classification Report:\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "         0.0       0.92      0.94      0.93     11821\n",
        "         1.0       0.95      0.93      0.94     14077\n",
        "\n",
        "      accuracy                           0.93     25898\n",
        "      macro avg      0.93      0.93      0.93     25898\n",
        "      weighted avg   0.93      0.93      0.93     25898"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hpJdPC-i58fI",
        "outputId": "d2cab8d0-fe3c-457d-f9b0-09ce978534b1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Given confusion matrix\n",
        "conf_matrix = np.array([[11104, 717], [1012, 13065]])\n",
        "\n",
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "# Calculate Sensitivity (True Positive Rate or Recall for the positive class)\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "\n",
        "# Calculate Specificity (True Negative Rate)\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4ZFFH6Q58fI",
        "outputId": "de4bc29b-0cbc-4ddd-c428-356ac55feafc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_test_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nLdJuqnL8v2"
      },
      "source": [
        "SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "3YsY24QSL88X",
        "outputId": "a62b75af-5ad6-48f0-dd49-bf2a67b230ec"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# dfc is my scaled and balanced dataframe\n",
        "X = dfc.drop('satisfaction', axis=1)\n",
        "y = dfc['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the SVM model\n",
        "svm_model = SVC()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],  \n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Use the best hyperparameters to train the final model\n",
        "final_model = SVC(**best_params, probability=True)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Initialize arrays to store predictions and true labels for the test set\n",
        "y_test_pred = np.array([])\n",
        "y_test_true = np.array([])\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = SVC(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "    # Store predictions and true labels for the test set\n",
        "    y_test_pred = np.concatenate((y_test_pred, final_model.predict(X_test.iloc[test_index])))\n",
        "    y_test_true = np.concatenate((y_test_true, y_test.iloc[test_index]))\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Accuracy: {mean_accuracy}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy}')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = accuracy_score(y_test_true, y_test_pred)\n",
        "conf_matrix = confusion_matrix(y_test_true, y_test_pred)\n",
        "classification_rep = classification_report(y_test_true, y_test_pred)\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip73Et1bV8p8"
      },
      "source": [
        "Best Hyperparameters: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
        "\n",
        "Accuracy: 0.9534088103551652\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[13651 518]\n",
        "\n",
        " [ 803 13381]]\n",
        "\n",
        "Classification Report:\n",
        "\n",
        "                  precision  recall   f1-score   support\n",
        "        0.0       0.94       0.96       0.95     14169\n",
        "        1.0       0.96       0.94       0.95     14184\n",
        "\n",
        "     accuracy                           0.95     28353\n",
        "     macro avg    0.95       0.95       0.95     28353\n",
        "     weighted avg 0.95       0.95       0.95     28353"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXkVHlos58fS",
        "outputId": "65ba8430-2953-4c20-ada5-9e2c2f4c6c5e"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Given confusion matrix\n",
        "conf_matrix = np.array([[13651, 518], [803, 13381]])\n",
        "\n",
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "# Calculate Sensitivity (True Positive Rate or Recall for the positive class)\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "\n",
        "# Calculate Specificity (True Negative Rate)\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3AcShSW58fT",
        "outputId": "a9e4ceea-f837-456c-a72f-38e83695471f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_test_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3_Qznv8OIi-"
      },
      "source": [
        "DT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMJU_baaOIqs"
      },
      "outputs": [],
      "source": [
        "# df2 is my SMOTE applied Dataframe\n",
        "X = df2.drop(columns = ['satisfaction'])\n",
        "y = df2['satisfaction']\n",
        "\n",
        "#Using SMOTE to balance the Data\n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 42)\n",
        "X, y = sm.fit_resample(X, y)\n",
        "pd.Series(y).value_counts()\n",
        "df2 = X.join(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5v7Lii1tOeGp",
        "outputId": "0470f011-b5fb-4c88-8d93-3537d6ed43f3"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# df2 is SMOTE\n",
        "X = df2.drop('satisfaction', axis=1)\n",
        "y = df2['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Decision Tree model\n",
        "dt_model = DecisionTreeClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'criterion': ['gini', 'entropy'],\n",
        "    'splitter': ['best', 'random'],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = DecisionTreeClassifier(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Accuracy: {mean_accuracy}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = DecisionTreeClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xqqyCE0X5kP"
      },
      "source": [
        "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}\n",
        "\n",
        "Accuracy: 0.9444150530808028\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[13505   664]\n",
        "\n",
        " [  912 13272]]\n",
        "\n",
        "\n",
        "Classification Report:\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.94      0.95      0.94     14169\n",
        "           1       0.95      0.94      0.94     14184\n",
        "\n",
        "    accuracy                           0.94     28353\n",
        "    macro avg       0.94      0.94     0.94     28353\n",
        "    weighted avg    0.94      0.94     0.94     28353"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 829
        },
        "id": "S5TNahMpuWv6",
        "outputId": "e56db91e-da95-4ade-a624-d3b3fe3048be"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  X_train and y_train are training data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Decision Tree model with the best hyperparameters\n",
        "best_params = {'criterion': 'gini', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 10, 'splitter': 'best'}\n",
        "final_model = DecisionTreeClassifier(**best_params)\n",
        "\n",
        "# Train the final model\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Visualize the Decision Tree\n",
        "plt.figure(figsize=(15, 10))\n",
        "plot_tree(final_model, filled=True, feature_names=X_train.columns, class_names=['Not Satisfied', 'Satisfied'])\n",
        "plt.title('Decision Tree Visualization')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iq5aGw6-Hzu-",
        "outputId": "38aa1583-b118-490e-e0fd-a1f8ff8ae699"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_test_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7rIDRQd58fY",
        "outputId": "c9dc7446-555c-4e32-878c-bfe33d35c8b7"
      },
      "outputs": [],
      "source": [
        "# Plot feature importances\n",
        "feature_importances = final_model.feature_importances_\n",
        "sorted_idx = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "# Plot the 10 most important features\n",
        "top_features = 10\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(top_features), feature_importances[sorted_idx][:top_features], align=\"center\")\n",
        "plt.xticks(range(top_features), X_train.columns[sorted_idx][:top_features], rotation=45)\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Feature Importance\")\n",
        "plt.title(\"Top 10 Feature Importances in DT Model\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mszBEZ2jH9RB"
      },
      "source": [
        "GB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egbrB30Amhwz",
        "outputId": "2cd54b68-da9e-4395-eced-c55ab4e06759"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, KFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "#  dfq is  DataFrame after SMOTE\n",
        "X = df2.drop('satisfaction', axis=1)\n",
        "y = df2['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=gb_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring='accuracy',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = GradientBoostingClassifier(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Accuracy: {mean_accuracy}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = GradientBoostingClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-_Uk1JjmnBc"
      },
      "source": [
        "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7,\n",
        "'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
        "\n",
        "Accuracy: 0.9608154339928755\n",
        "\n",
        "Confusion Matrix:\n",
        "\n",
        "[[13758 411]\n",
        "\n",
        "[ 700 13484]]\n",
        "\n",
        "Classification Report:\n",
        "\n",
        "                     precision       recall       f1-score      support\n",
        "\n",
        "             0        0.95            0.97         0.96          14169\n",
        "             1        0.97            0.95         0.96          14184\n",
        "\n",
        "       accuracy                                  0.96          28353\n",
        "       macro avg     0.96           0.96         0.96          28353\n",
        "       weighted avg  0.96           0.96         0.96          28353"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBtGSnXPIAbb",
        "outputId": "403003b0-6f4d-4792-9686-f930bc13978d"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_test_pred_proba = random_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Uk3jbNAQPdV"
      },
      "source": [
        "RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "CVqQO3MKQPom",
        "outputId": "62db582b-4cf0-4900-8e0e-69cdc388e266"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "#  df2 is  DataFrame after SMOTE\n",
        "X = df2.drop('satisfaction', axis=1)\n",
        "y = df2['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = RandomForestClassifier(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Accuracy: {mean_accuracy}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = RandomForestClassifier(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLm-FR9K0vzG"
      },
      "source": [
        "Best Hyperparameters: {'bootstrap': False, 'max_depth': 30,\n",
        "'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
        "\n",
        "Accuracy: 0.9613092089020562\n",
        "\n",
        " Confusion Matrix:\n",
        "\n",
        "  [[13776 393]\n",
        "\n",
        "   [ 704 13480]]\n",
        "\n",
        "Classification Report:\n",
        "\n",
        "                        precision      recall     f1-score      support\n",
        "            0             0.95          0.97        0.96        14169\n",
        "            1             0.97         0.95         0.96        14184\n",
        "            \n",
        "     accuracy                                       0.96        28353\n",
        "     macroavg             0.96         0.96         0.96        28353\n",
        "     weighted avg         0.96         0.96         0.96        28353\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RnE_XAhIHqC",
        "outputId": "c6d2cd13-c450-4437-b8ae-4d24df101266"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_test_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyqQtgl958fd",
        "outputId": "6ec09837-f069-40aa-c85e-47465a5a29cd"
      },
      "outputs": [],
      "source": [
        "# Plot feature importances\n",
        "feature_importances = final_model.feature_importances_\n",
        "sorted_idx = np.argsort(feature_importances)[::-1]\n",
        "\n",
        "# Plot the 10 most important features\n",
        "top_features = 10\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(top_features), feature_importances[sorted_idx][:top_features], align=\"center\")\n",
        "plt.xticks(range(top_features), X_train.columns[sorted_idx][:top_features], rotation=45)\n",
        "plt.xlabel(\"Feature\")\n",
        "plt.ylabel(\"Feature Importance\")\n",
        "plt.title(\"Top 10 Feature Importances in Random Forest Model\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoQfjYSV1QWJ"
      },
      "source": [
        "AdaBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aNxG2FP41QiM",
        "outputId": "212c17fe-9756-4020-ccce-ce15e2a6858b"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "#  df2 is SMOTE applied df\n",
        "X = df2.drop('satisfaction', axis=1) \n",
        "y = df2['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the AdaBoost model\n",
        "adaboost_model = AdaBoostClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.1, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=adaboost_model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_n_estimators = best_params['n_estimators']\n",
        "best_learning_rate = best_params['learning_rate']\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
        "\n",
        "    # Initialize AdaBoost model with the best hyperparameters\n",
        "    final_model = AdaBoostClassifier(n_estimators=best_n_estimators, learning_rate=best_learning_rate)\n",
        "\n",
        "    # Fit the model to the training fold\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = pd.Series(accuracy_scores).mean()\n",
        "std_accuracy = pd.Series(accuracy_scores).std()\n",
        "\n",
        "# Print the best hyperparameters and evaluation metric\n",
        "print(f\"Best Number of Estimators: {best_n_estimators}\")\n",
        "print(f\"Best Learning Rate: {best_learning_rate}\")\n",
        "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
        "print(f\"Standard Deviation of Accuracy: {std_accuracy:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Print additional metrics on the test set\n",
        "print(\"Test Set Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZGz6ijl58ff",
        "outputId": "2c39c230-cd19-409a-c62c-4e9c0278b6e6"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_test_pred_proba = grid_search.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D85LbWZc5V7K"
      },
      "source": [
        "CatBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYp-EqhI5WGI",
        "outputId": "be67538c-30b0-47e8-f9a2-8c6ce217c8ef"
      },
      "outputs": [],
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# df is not balanced or scaled\n",
        "X = df.drop('satisfaction', axis=1)\n",
        "y = df['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CatBoost model\n",
        "catboost_model = CatBoostClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'iterations': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],  # Fix the typo here\n",
        "    'depth': [6, 8, 10],\n",
        "    'l2_leaf_reg': [1, 3, 5]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=catboost_model, param_grid=param_grid, scoring='accuracy', cv=5)\n",
        "\n",
        "# Fit the model to the training data\n",
        "grid_search.fit(X_train, y_train, cat_features=None, verbose=0)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_iterations = best_params['iterations']\n",
        "best_learning_rate = best_params['learning_rate']\n",
        "best_depth = best_params['depth']\n",
        "best_l2_leaf_reg = best_params['l2_leaf_reg']\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f\"Best Iterations: {best_iterations}\")\n",
        "print(f\"Best Learning Rate: {best_learning_rate}\")\n",
        "print(f\"Best Depth: {best_depth}\")\n",
        "print(f\"Best L2 Leaf Regularization: {best_l2_leaf_reg}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X_train)):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Initialize CatBoost model with the best hyperparameters\n",
        "    final_model = CatBoostClassifier(\n",
        "        iterations=best_iterations,\n",
        "        learning_rate=best_learning_rate,\n",
        "        depth=best_depth,\n",
        "        l2_leaf_reg=best_l2_leaf_reg\n",
        "    )\n",
        "\n",
        "    # Fit the model to the training fold\n",
        "    final_model.fit(X_train_fold, y_train_fold, cat_features=None, verbose=0)\n",
        "\n",
        "    # Make predictions on the validation fold\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "    print(f\"Fold {fold + 1}: Accuracy = {fold_accuracy:.4f}\")\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = pd.Series(accuracy_scores).mean()\n",
        "std_accuracy = pd.Series(accuracy_scores).std()\n",
        "\n",
        "# Print the mean and standard deviation of accuracy scores\n",
        "print(f\"\\nMean Accuracy: {mean_accuracy:.4f}\")\n",
        "print(f\"Standard Deviation of Accuracy: {std_accuracy:.4f}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_test_pred = grid_search.predict(X_test)\n",
        "print(\"Test Set Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7tM7aPS5b2j",
        "outputId": "53af5eb3-4176-4ab1-eab6-071c412f7e39"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get predicted probabilities for the positive class\n",
        "y_test_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxE0WtTl58fj",
        "outputId": "e9c29030-dce2-4494-cafa-138d8e47cfc8"
      },
      "outputs": [],
      "source": [
        "# Given confusion matrix\n",
        "conf_matrix = np.array([[11430, 391], [623, 13454]])\n",
        "\n",
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "# Calculate Sensitivity (True Positive Rate or Recall for the positive class)\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "\n",
        "# Calculate Specificity (True Negative Rate)\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzq2_E4X58fk"
      },
      "source": [
        "NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mpe__Jr58fk",
        "outputId": "468fc56b-37fe-4dca-a645-b60a2485f258"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#  dfq is  DataFrame after SMOTE\n",
        "X = df.drop('satisfaction', axis=1)\n",
        "y = df['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Neural Network model\n",
        "mlp_model = MLPClassifier(max_iter=1000, random_state=42)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50)],\n",
        "    'activation': ['logistic', 'tanh', 'relu'],\n",
        "    'alpha': [0.0001, 0.001, 0.01],\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=mlp_model, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy scores for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = MLPClassifier(max_iter=1000, random_state=42, **best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Accuracy: {mean_accuracy}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = MLPClassifier(max_iter=1000, random_state=42, **best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94ZTtl-H58fl",
        "outputId": "2d82f0c9-32d8-43a6-e530-e68f3eb9ba11"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  dfq is  DataFrame after SMOTE\n",
        "X = df.drop('satisfaction', axis=1)\n",
        "y = df['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the Neural Network model with the best hyperparameters\n",
        "best_params = {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (100,)}\n",
        "mlp_model = MLPClassifier(max_iter=1000, random_state=42, **best_params)\n",
        "\n",
        "# Fit the model on the training set\n",
        "mlp_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predicted probabilities for the test set\n",
        "y_val_prob = mlp_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "#  y_test and y_pred are  true labels and predicted probabilities\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_val_prob)\n",
        "\n",
        "# Calculate the AUC score\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRHfBxUw58fm",
        "outputId": "2f6e776a-17a8-42a5-9a26-c0b2775199dc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import RocCurveDisplay, auc\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#  dfq is  DataFrame after SMOTE\n",
        "X = df.drop('satisfaction', axis=1)\n",
        "y = df['satisfaction']\n",
        "\n",
        "# Define the Neural Network model with the best hyperparameters\n",
        "best_params = {'activation': 'logistic', 'alpha': 0.001, 'hidden_layer_sizes': (100,)}\n",
        "mlp_model = MLPClassifier(max_iter=1000, random_state=42, **best_params)\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize arrays to store true positive rates and area under the ROC curve for each fold\n",
        "tprs = []\n",
        "aucs = []\n",
        "\n",
        "# Initialize mean false positive rate array\n",
        "mean_fpr = np.linspace(0, 1, 100)\n",
        "\n",
        "# Initialize the plot\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X)):\n",
        "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Train the final model\n",
        "    mlp_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Get predicted probabilities for positive class\n",
        "    y_val_prob = mlp_model.predict_proba(X_val_fold)[:, 1]\n",
        "\n",
        "    # Compute ROC curve and area under the curve\n",
        "    fpr, tpr, _ = roc_curve(y_val_fold, y_val_prob)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Plot ROC curve for each fold\n",
        "    roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc, estimator_name=f\"Fold {fold}\")\n",
        "    roc_display.plot(ax=ax, alpha=0.3, lw=1)\n",
        "\n",
        "    # Interpolate true positive rates to mean false positive rate\n",
        "    interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
        "    interp_tpr[0] = 0.0\n",
        "    tprs.append(interp_tpr)\n",
        "    aucs.append(roc_auc)\n",
        "\n",
        "# Plot mean ROC curve\n",
        "mean_tpr = np.mean(tprs, axis=0)\n",
        "mean_tpr[-1] = 1.0\n",
        "mean_auc = auc(mean_fpr, mean_tpr)\n",
        "\n",
        "ax.plot(\n",
        "    mean_fpr,\n",
        "    mean_tpr,\n",
        "    color=\"b\",\n",
        "    label=f\"Mean ROC (AUC = {mean_auc:.2f})\",\n",
        "    lw=2,\n",
        "    alpha=0.8,\n",
        ")\n",
        "\n",
        "# Plot chance level\n",
        "ax.plot([0, 1], [0, 1], linestyle=\"--\", color=\"grey\", lw=2, label=\"Chance\", alpha=0.8)\n",
        "\n",
        "# Set plot properties\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel(\"False Positive Rate\")\n",
        "ax.set_ylabel(\"True Positive Rate\")\n",
        "ax.set_title(\"ROC Curve with k-fold Cross-Validation\")\n",
        "ax.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Train the final model on the entire dataset\n",
        "mlp_model.fit(X, y)\n",
        "\n",
        "# Get predictions on the entire dataset\n",
        "y_pred = mlp_model.predict(X)\n",
        "\n",
        "# Generate confusion matrix for the entire dataset\n",
        "conf_mat = confusion_matrix(y, y_pred)\n",
        "pring(conf_mat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iurRBn8258fn",
        "outputId": "99c14424-a25b-47a0-c191-8954e2d022c9"
      },
      "outputs": [],
      "source": [
        "# Given confusion matrix\n",
        "conf_matrix = np.array([[11212, 609], [1641, 12436]])\n",
        "\n",
        "# Extract values from confusion matrix\n",
        "tn, fp, fn, tp = conf_matrix.ravel()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
        "precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "# Calculate Sensitivity (True Positive Rate or Recall for the positive class)\n",
        "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "\n",
        "# Calculate Specificity (True Negative Rate)\n",
        "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "print(f\"Specificity: {specificity:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UalyuFDXSBw"
      },
      "source": [
        "Logistic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPFWMXH-XSNZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "X = dfc.drop('satisfaction', axis=1)\n",
        "y = dfc['satisfaction']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the logistic regression model\n",
        "logreg_model = LogisticRegression()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_dist = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'C': np.logspace(-4, 4, 20),\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(logreg_model, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', verbose=1, n_jobs=-1, random_state=42)\n",
        "\n",
        "# Fit the model with hyperparameter tuning on the training set\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "# Initialize KFold cross-validation\n",
        "k_folds = 10\n",
        "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize an array to store accuracy for each fold\n",
        "accuracy_scores = []\n",
        "\n",
        "# Perform k-fold cross-validation\n",
        "for train_index, val_index in kf.split(X_train):\n",
        "    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
        "    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
        "\n",
        "    # Use the best hyperparameters to train the final model\n",
        "    final_model = LogisticRegression(**best_params)\n",
        "    final_model.fit(X_train_fold, y_train_fold)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_val_pred = final_model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate accuracy for the fold\n",
        "    fold_accuracy = accuracy_score(y_val_fold, y_val_pred)\n",
        "    accuracy_scores.append(fold_accuracy)\n",
        "\n",
        "# Calculate mean and standard deviation of accuracy scores\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "\n",
        "# Print the best hyperparameters and evaluation metrics\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy:.4f}')\n",
        "\n",
        "# Use the best hyperparameters to train the final model on the entire training set\n",
        "final_model = LogisticRegression(**best_params)\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = final_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f'Accuracy on Test Set: {accuracy:.4f}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{classification_rep}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh0dW0ogYii0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "y_pred = final_model.predict_proba(X_test)[:, 1]\n",
        "#  y_test and y_pred are  true labels and predicted probabilities\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "\n",
        "# Calculate the AUC score\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I5yW2e-DYGm"
      },
      "source": [
        "#Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kmeans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df1 is sclaed df\n",
        "X = df1.drop('satisfaction', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Number of clusters:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "elbow method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  X is  data\n",
        "distortions = []\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeanModel = KMeans(n_clusters=k)\n",
        "    kmeanModel.fit(X)\n",
        "    distortions.append(kmeanModel.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(K_range, distortions, marker='o')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Distortion (SSD)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Silhouette Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "silhouette_scores = []\n",
        "K_range = range(2, 11)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeanModel = KMeans(n_clusters=k)\n",
        "    kmeanModel.fit(X)\n",
        "    labels = kmeanModel.labels_\n",
        "    silhouette_scores.append(silhouette_score(X, labels))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(K_range, silhouette_scores, marker='o')\n",
        "plt.title('Silhouette Score for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gap Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import pairwise_distances\n",
        "from gap_statistic import OptimalK\n",
        "\n",
        "optimalK = OptimalK(parallel_backend='joblib')\n",
        "n_clusters = optimalK(X, cluster_array=np.arange(1, 11))\n",
        "print(f'Optimal number of clusters: {n_clusters}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Davies-Bouldin Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import davies_bouldin_score\n",
        "\n",
        "K_range = range(2, 11)\n",
        "db_scores = []\n",
        "\n",
        "for k in K_range:\n",
        "    kmeanModel = KMeans(n_clusters=k)\n",
        "    kmeanModel.fit(X)\n",
        "    labels = kmeanModel.labels_\n",
        "    db_scores.append(davies_bouldin_score(X, labels))\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(K_range, db_scores, marker='o')\n",
        "plt.title('Davies-Bouldin Index for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Davies-Bouldin Index')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "kmeans model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "## df1 is scaled df\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "y = df1['satisfaction']\n",
        "\n",
        "# Set the number of clusters for k-means\n",
        "n_clusters = 3\n",
        "\n",
        "# Initialize k-means clustering with K-means++ initialization\n",
        "kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
        "y_pred = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, y_pred)\n",
        "silhouette = silhouette_score(X_scaled, y_pred)\n",
        "chs = calinski_harabasz_score(X_scaled, y_pred)\n",
        "\n",
        "# Additional evaluation metrics for labeled data ( 'customer_satisfaction' is the label)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], y_pred)\n",
        "jaccard = jaccard_score(df1['satisfaction'], y_pred, average='weighted')\n",
        "\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "\n",
        "print(f'Adjusted Rand Index (ARI): {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "visualizing KMEANS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Apply PCA to reduce dimensionality to 2\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Visualize the clustering results using a scatter plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y_pred, palette='viridis', legend='full')\n",
        "plt.title('K-Means Clustering Results (PCA)')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "\n",
        "# Assume X_scaled is your scaled data\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Get the principal components\n",
        "components_df = pd.DataFrame(pca.components_, columns=X_scaled.columns)\n",
        "\n",
        "# Display the principal components\n",
        "print(\"Principal Components:\")\n",
        "print(components_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas.plotting import radviz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df1['Cluster'] = y_pred\n",
        "\n",
        "# Define a list of colors for each cluster\n",
        "cluster_colors = ['red', 'green', 'blue']\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(27, 10))\n",
        "\n",
        "# Visualize RadViz for each cluster separately\n",
        "for cluster_num, color in zip(range(n_clusters), cluster_colors):\n",
        "    plt.subplot(1, n_clusters, cluster_num + 1)\n",
        "    cluster_data = df1[df1['Cluster'] == cluster_num]\n",
        "    \n",
        "    radviz(cluster_data, class_column='Cluster', color=color, alpha=0.5)\n",
        "    plt.title(f'Cluster {cluster_num}')\n",
        "    plt.xlabel('')\n",
        "    plt.ylabel('')\n",
        "\n",
        "plt.suptitle('RadViz - Clustering Visualization for Each Cluster', y=1.02)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df1['Cluster'] = y_pred\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Create a heatmap\n",
        "sns.heatmap(df1.groupby('Cluster').mean(), cmap='viridis', annot=True, fmt=\".2f\")\n",
        "plt.title('Cluster Feature Means - Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "neighborhood size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Elbow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  X_scaled is  standardized data\n",
        "neigh = NearestNeighbors(n_neighbors=2)\n",
        "nbrs = neigh.fit(X_scaled)\n",
        "distances, indices = nbrs.kneighbors(X_scaled)\n",
        "\n",
        "distances = np.sort(distances, axis=0)\n",
        "distances = distances[:, 1]\n",
        "\n",
        "plt.plot(distances)\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance to 2nd Nearest Neighbor')\n",
        "plt.title('Elbow Method for DBSCAN eps')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DBSCAN hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "\n",
        "eps_values = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,1.1,1.2,1,5]  \n",
        "silhouette_scores = []\n",
        "\n",
        "for eps in eps_values:\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=5)\n",
        "    labels = dbscan.fit_predict(X_scaled)\n",
        "    silhouette_scores.append(silhouette_score(X_scaled, labels))\n",
        "\n",
        "best_eps = eps_values[np.argmax(silhouette_scores)]\n",
        "print(f'Best eps value: {best_eps}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best eps value: 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "#  X_scaled is  standardized data and y is  labels\n",
        "min_samples_values = [3, 5, 7, 10]  \n",
        "eps = 1  \n",
        "\n",
        "best_score = -1\n",
        "best_min_samples = None\n",
        "\n",
        "for min_samples in min_samples_values:\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    labels = dbscan.fit_predict(X_scaled)\n",
        "    score = adjusted_rand_score(y, labels)  #  y is  true labels\n",
        "    print(f'Min Samples: {min_samples}, Adjusted Rand Score: {score}')\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_min_samples = min_samples\n",
        "\n",
        "print(f'Best Min Samples: {best_min_samples}, Best Adjusted Rand Score: {best_score}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "y = df1['satisfaction']\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "metrics_to_try = ['euclidean', 'manhattan', 'cosine', 'minkowski', 'chebyshev']\n",
        "\n",
        "best_metric = None\n",
        "best_silhouette_score = -1\n",
        "\n",
        "for metric in metrics_to_try:\n",
        "    dbscan = DBSCAN(eps=1, min_samples=3, metric=metric)\n",
        "    labels = dbscan.fit_predict(X_scaled)\n",
        "    silhouette = silhouette_score(X_scaled, labels)\n",
        "    \n",
        "    print(f'Metric: {metric}, Silhouette Score: {silhouette}')\n",
        "    \n",
        "    if silhouette > best_silhouette_score:\n",
        "        best_silhouette_score = silhouette\n",
        "        best_metric = metric\n",
        "\n",
        "print(f'Best Metric: {best_metric}, Best Silhouette Score: {best_silhouette_score}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Best Metric: euclidean, Best Silhouette Score: 0.1348404334465667"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DBSCAN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "## df1 is scaled df\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Set the parameters for DBSCAN\n",
        "eps = 1\n",
        "min_samples = 3  \n",
        "\n",
        "# Initialize DBSCAN clustering\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='euclidean')\n",
        "labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, labels)\n",
        "silhouette = silhouette_score(X_scaled, labels)\n",
        "chs = calinski_harabasz_score(X_scaled, labels)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], labels)\n",
        "jaccard = jaccard_score(df1['satisfaction'], labels, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "print(f'Adjusted Rand Index: {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n",
        "\n",
        "# Visualize clusters using PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a DataFrame with PCA components and cluster labels\n",
        "df_pca = pd.DataFrame({'PCA1': X_pca[:, 0], 'PCA2': X_pca[:, 1], 'Cluster': labels})\n",
        "\n",
        "# Plot the clusters\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df_pca, palette='viridis', legend='full')\n",
        "plt.title('DBSCAN Clusters (PCA)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "noise_points_count = np.count_nonzero(labels == -1)\n",
        "noise_points_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df1['Cluster'] = y_pred\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Create a heatmap\n",
        "sns.heatmap(df1.groupby('Cluster').mean(), cmap='coolwarm', annot=True, fmt=\".2f\")\n",
        "plt.title('Cluster Feature Means - Heatmap')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas.plotting import radviz\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "df1['Cluster'] = y_pred\n",
        "\n",
        "# Define a list of colors for each cluster\n",
        "cluster_colors = ['purple', 'orange', 'gray']\n",
        "\n",
        "# Increase the figure size\n",
        "plt.figure(figsize=(27, 10))\n",
        "\n",
        "# Adjust font size for better readability\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# Visualize RadViz for each cluster separately\n",
        "for cluster_num, color in zip(range(n_clusters), cluster_colors):\n",
        "    plt.subplot(1, n_clusters, cluster_num + 1)\n",
        "    cluster_data = df1[df1['Cluster'] == cluster_num]\n",
        "    \n",
        "    radviz(cluster_data, class_column='Cluster', color=color, alpha=0.3)  # Reduce transparency\n",
        "    plt.title(f'Cluster {cluster_num}')\n",
        "    plt.xlabel('')\n",
        "    plt.ylabel('')\n",
        "\n",
        "# Adjust the distance between subplots\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "\n",
        "plt.suptitle('RadViz - Clustering Visualization for Each Cluster', y=1.2, fontsize=16)  # Adjust title font size\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Davies-Bouldin Index: 2.6003055701454496\n",
        "Silhouette Score: 0.1348404334465667\n",
        "Calinski-Harabasz Score: 8155.810398563863\n",
        "Adjusted Rand Index: 0.09935302975746158\n",
        "Jaccard Score: 0.1590090402579417"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HDBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import silhouette_score\n",
        "import hdbscan\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "\n",
        "# Define the parameter grid for random search\n",
        "param_dist = {\n",
        "    'min_cluster_size': [5, 10, 15],\n",
        "    'min_samples': [2, 3, 5, 7],\n",
        "}\n",
        "\n",
        "# Define silhouette scorer for optimization\n",
        "silhouette_scorer = make_scorer(silhouette_score)\n",
        "\n",
        "# Initialize HDBSCAN\n",
        "hdb = hdbscan.HDBSCAN()\n",
        "\n",
        "# Perform random search\n",
        "random_search = RandomizedSearchCV(hdb, param_distributions=param_dist, scoring=silhouette_scorer, n_iter=50, cv=5)\n",
        "random_search.fit(X_scaled)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "\n",
        "best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "HDBSCAN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize HDBSCAN clustering\n",
        "hdb = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=2)\n",
        "y_pred = hdb.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "try:\n",
        "    dbi = davies_bouldin_score(X_scaled, y_pred)\n",
        "except ValueError:\n",
        "    dbi = float('nan')\n",
        "\n",
        "silhouette = silhouette_score(X_scaled, y_pred)\n",
        "chs = calinski_harabasz_score(X_scaled, y_pred)\n",
        "\n",
        "# Additional evaluation metrics for labeled data ( 'y' is the label)\n",
        "ari = adjusted_rand_score(y, y_pred)\n",
        "jaccard = jaccard_score(y, y_pred, average='weighted')\n",
        "\n",
        "# Print the evaluation metrics\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "print(f'Adjusted Rand Index (ARI): {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "import hdbscan\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#  X_scaled is  feature matrix\n",
        "hdbscan_model = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=2)  \n",
        "labels = hdbscan_model.fit_predict(X_scaled)\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a scatter plot with different colors for each cluster\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i, color in zip(unique_labels, colors):\n",
        "    class_member_mask = (labels == i)\n",
        "    xy = X_pca[class_member_mask]\n",
        "    plt.scatter(xy[:, 0], xy[:, 1], c=[color], edgecolor='k', s=50, alpha=0.7)\n",
        "\n",
        "plt.title('HDBSCAN Clustering with PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hierarchical clustering (unfortunately Kernel Crashed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hyperparam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  X is  feature matrix and Z is the linkage matrix\n",
        "X = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "Z = linkage(X, method='ward')\n",
        "plt.figure(figsize=(12, 6))\n",
        "dendrogram(Z)\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hierarchical model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score, jaccard_score\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "\n",
        "#  X is  feature matrix\n",
        "X = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "Z = linkage(X, method='ward')\n",
        "\n",
        "# Set the number of clusters (you can choose based on dendrogram)\n",
        "n_clusters = 3\n",
        "\n",
        "# Fit AgglomerativeClustering model\n",
        "model = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "labels = model.fit_predict(X)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "silhouette = silhouette_score(X, labels)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], labels)\n",
        "jaccard = jaccard_score(df1['satisfaction'], labels, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Adjusted Rand Index: {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n",
        "\n",
        "# Visualize dendrogram\n",
        "plt.figure(figsize=(12, 6))\n",
        "dendrogram(Z)\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MEAN shift"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hyperparam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
        "from sklearn.metrics import silhouette_score, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "## df1 is scaled df\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Estimate bandwidth using sklearn's function\n",
        "bandwidth = estimate_bandwidth(X_scaled, quantile=0.2, n_samples=500)\n",
        "\n",
        "# Initialize Mean Shift clustering\n",
        "meanshift = MeanShift(bandwidth=bandwidth)\n",
        "\n",
        "# Define parameter grid for bandwidth\n",
        "param_grid = {'bandwidth': [0.1, 0.5, 1.0]}\n",
        "\n",
        "# Define a custom silhouette scorer\n",
        "silhouette_scorer = make_scorer(silhouette_score)\n",
        "\n",
        "# Perform GridSearchCV using the custom silhouette scorer\n",
        "grid_search = GridSearchCV(meanshift, param_grid=param_grid, cv=5, scoring=silhouette_scorer, n_jobs=-1)\n",
        "grid_search.fit(X_scaled)\n",
        "\n",
        "# Get the best parameters\n",
        "best_bandwidth = grid_search.best_params_['bandwidth']\n",
        "\n",
        "# Initialize Mean Shift clustering with the best bandwidth\n",
        "best_meanshift = MeanShift(bandwidth=best_bandwidth)\n",
        "y_pred_best = best_meanshift.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "silhouette_best = silhouette_score(X_scaled, y_pred_best)\n",
        "\n",
        "print(f'Best Bandwidth: {best_bandwidth}')\n",
        "print(f'Silhouette Score: {silhouette_best}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "high runtime causes using another method based on Sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Meanshift Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import MeanShift\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# The following bandwidth can be automatically detected using\n",
        "# bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=500)\n",
        "\n",
        "## df1 is scaled df\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Initialize Mean Shift clustering\n",
        "meanshift = MeanShift(bandwidth=0.1)\n",
        "y_pred = meanshift.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, y_pred)\n",
        "silhouette = silhouette_score(X_scaled, y_pred)\n",
        "chs = calinski_harabasz_score(X_scaled, y_pred)\n",
        "\n",
        "# Additional evaluation metrics for labeled data\n",
        "ari = adjusted_rand_score(y, y_pred)\n",
        "jaccard = jaccard_score(y, y_pred, average='weighted')\n",
        "\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "\n",
        "print(f'Adjusted Rand Index (ARI): {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import MeanShift\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#  X_scaled is  feature matrix\n",
        "meanshift = MeanShift(bandwidth=0.1)\n",
        "labels = meanshift.fit_predict(X_scaled)\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a scatter plot with different colors for each cluster\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i, color in zip(unique_labels, colors):\n",
        "    class_member_mask = (labels == i)\n",
        "    xy = X_pca[class_member_mask, :]\n",
        "    plt.scatter(xy[:, 0], xy[:, 1], c=[color], edgecolor='k', s=50, alpha=0.7)\n",
        "\n",
        "plt.title('Mean Shift Clustering with PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gaussion MM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hyperparam GMM Method1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "#  X is  feature matrix\n",
        "X = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Define the range of n_components to search over\n",
        "n_components_range = range(2, 6)\n",
        "\n",
        "# Perform a grid search\n",
        "best_n_components = None\n",
        "best_aic = float('inf')  # Initialize with a large value\n",
        "for n_components in n_components_range:\n",
        "    gmm = GaussianMixture(n_components=n_components)\n",
        "    gmm.fit(X)\n",
        "    aic = gmm.aic(X)\n",
        "    if aic < best_aic:\n",
        "        best_aic = aic\n",
        "        best_n_components = n_components\n",
        "\n",
        "print(f\"Best n_components: {best_n_components}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GMM model based on n_component=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the number of clusters for GMM\n",
        "n_components = 5\n",
        "\n",
        "\n",
        "## df1 is scaled df\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Initialize Gaussian Mixture Model clustering\n",
        "gmm = GaussianMixture(n_components=n_components, random_state=42)\n",
        "y_pred = gmm.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, y_pred)\n",
        "silhouette = silhouette_score(X_scaled, y_pred)\n",
        "chs = calinski_harabasz_score(X_scaled, y_pred)\n",
        "\n",
        "# Additional evaluation metrics for labeled data ( 'satisfaction' is the label)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], y_pred)\n",
        "jaccard = jaccard_score(df1['satisfaction'], y_pred, average='weighted')\n",
        "\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "\n",
        "print(f'Adjusted Rand Index (ARI): {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "hyperparam GMM Method2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "#  X is  feature matrix\n",
        "X = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Define the range of n_components to search over\n",
        "n_components_range = range(2, 6)\n",
        "\n",
        "# Evaluate silhouette score for each n_components\n",
        "silhouette_scores = []\n",
        "for n_components in n_components_range:\n",
        "    gmm = GaussianMixture(n_components=n_components)\n",
        "    labels = gmm.fit_predict(X)\n",
        "    silhouette_scores.append(silhouette_score(X, labels))\n",
        "\n",
        "best_n_components = n_components_range[np.argmax(silhouette_scores)]\n",
        "print(f\"Best n_components (Silhouette Score): {best_n_components}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "it is better to select number of component parallel with covariance type for being more accurate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "\n",
        "# Set the hyperparameters to tune\n",
        "param_grid = {\n",
        "    'n_components': [2, 3, 4, 5], \n",
        "    'covariance_type': ['full', 'tied', 'diag', 'spherical'],\n",
        "}\n",
        "\n",
        "# Initialize Gaussian Mixture Model\n",
        "gmm = GaussianMixture(random_state=42)\n",
        "\n",
        "# Define a custom silhouette scorer\n",
        "silhouette_scorer = make_scorer(silhouette_score)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(gmm, param_grid=param_grid, cv=5, scoring=silhouette_scorer, n_jobs=-1)\n",
        "\n",
        "# Fit the model to find the best hyperparameters\n",
        "grid_search.fit(X_scaled)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "best_gmm = grid_search.best_estimator_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f'Best Hyperparameters: {best_params}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "GMM model based on Best Hyperparameters: {'covariance_type': 'full', 'n_components': 2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the number of clusters for GMM\n",
        "n_components = 2\n",
        "covariance_type = 'full'\n",
        "\n",
        "## df1 is scaled df\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Initialize Gaussian Mixture Model clustering\n",
        "gmm = GaussianMixture(n_components=n_components, covariance_type=covariance_type, random_state=42)\n",
        "y_pred = gmm.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, y_pred)\n",
        "silhouette = silhouette_score(X_scaled, y_pred)\n",
        "chs = calinski_harabasz_score(X_scaled, y_pred)\n",
        "\n",
        "# Additional evaluation metrics for labeled data ( 'satisfaction' is the label)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], y_pred)\n",
        "jaccard = jaccard_score(df1['satisfaction'], y_pred, average='weighted')\n",
        "\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "\n",
        "print(f'Adjusted Rand Index (ARI): {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OPTICS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import OPTICS\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the data\n",
        "y = df1['satisfaction']\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'min_samples': [3, 5, 7],\n",
        "    'xi': [0.01, 0.05, 0.1]\n",
        "}\n",
        "\n",
        "# Initialize OPTICS clustering\n",
        "optics = OPTICS()\n",
        "\n",
        "# Define a custom silhouette scorer\n",
        "silhouette_scorer = make_scorer(silhouette_score)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(optics, param_grid=param_grid, cv=5, scoring=silhouette_scorer, n_jobs=-1)\n",
        "\n",
        "# Fit the model to find the best hyperparameters\n",
        "grid_search.fit(X_scaled)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(f'Best Hyperparameters: {best_params}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "elbow method for min_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import OPTICS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "optics = OPTICS(xi=0.01)\n",
        "optics.fit(X_scaled)\n",
        "\n",
        "reachability = optics.reachability_[optics.ordering_]\n",
        "plt.plot(reachability)\n",
        "plt.title(\"OPTICS Reachability Plot\")\n",
        "plt.xlabel(\"Ordered Data Points\")\n",
        "plt.ylabel(\"Reachability Distance\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are two basic ways to extract clusters from the reachability plot – manual and automatic using different algorithms. The manual way refers to either setting the range on the x-axis or using the threshold on the y-axis after performing the visual inspection of the reachability plot. Generally, clusters appear as valleys on the reachability plot so that deeper valleys represent dense clusters, while shallow valleys represent sparse clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " The reachability plot showing the ordering returned by the OPTICS algorithm visibly has 3 valleys corresponding to the three identified clusters. We can see that the densest cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OPTICS model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import OPTICS\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "\n",
        "# Standardize the data\n",
        "y = df1['satisfaction']\n",
        "X_scaled = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Initialize OPTICS clustering\n",
        "optics = OPTICS(xi=0.01, min_cluster_size=3)\n",
        "\n",
        "# Fit the model on the entire dataset\n",
        "y_pred = optics.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, y_pred)\n",
        "silhouette = silhouette_score(X_scaled, y_pred)\n",
        "chs = calinski_harabasz_score(X_scaled, y_pred)\n",
        "\n",
        "# Additional evaluation metrics for labeled data\n",
        "ari = adjusted_rand_score(y, y_pred)\n",
        "jaccard = jaccard_score(y, y_pred, average='weighted')\n",
        "\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "print(f'Adjusted Rand Index (ARI): {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import OPTICS\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#  X_scaled is  feature matrix\n",
        "optics = OPTICS(min_samples=3, xi=0.01, min_cluster_size=3) \n",
        "labels = optics.fit_predict(X_scaled)\n",
        "\n",
        "# Apply PCA to reduce dimensionality\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a scatter plot with different colors for each cluster\n",
        "unique_labels = set(labels)\n",
        "colors = [plt.cm.Spectral(each) for each in np.linspace(0, 1, len(unique_labels))]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i, color in zip(unique_labels, colors):\n",
        "    class_member_mask = (labels == i)\n",
        "    xy = X_pca[class_member_mask, :]\n",
        "    plt.scatter(xy[:, 0], xy[:, 1], c=[color], edgecolor='k', s=50, alpha=0.7)\n",
        "\n",
        "plt.title('OPTICS Clustering with PCA')\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = df3.drop('satisfaction', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X['Delays'] = X['Departure Delay in Minutes'] + X['Departure/Arrival time convenient']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X['DPD'] = X['Delays']/X['Flight Distance']\n",
        "X['D*D'] = X['Delays']*X['Flight Distance']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1 = X[['DPD','Total_Score','Age']]\n",
        "X2 = X[['D*D','Total_Score','Age']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#scalling process specified for X1\n",
        "c = X1.columns\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "Scaler = MinMaxScaler()\n",
        "X1 = Scaler.fit_transform(X1)\n",
        "\n",
        "X1 = pd.DataFrame(X1)\n",
        "\n",
        "X1.columns = c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "K-means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "distortions = []\n",
        "K_range = range(2, 9)\n",
        "\n",
        "for k in K_range:\n",
        "    kmeanModel = KMeans(n_clusters=k)\n",
        "    kmeanModel.fit(X1)\n",
        "    distortions.append(kmeanModel.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(K_range, distortions, marker='o')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Distortion (SSD)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "## df1 is scaled df\n",
        "X_scaled = X1\n",
        "y = df1['satisfaction']\n",
        "\n",
        "# Set the number of clusters for k-means\n",
        "n_clusters = 3\n",
        "\n",
        "# Initialize k-means clustering with K-means++ initialization\n",
        "kmeans = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\n",
        "y_pred = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, y_pred)\n",
        "silhouette = silhouette_score(X_scaled, y_pred)\n",
        "chs = calinski_harabasz_score(X_scaled, y_pred)\n",
        "\n",
        "# Additional evaluation metrics for labeled data ( 'customer_satisfaction' is the label)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], y_pred)\n",
        "jaccard = jaccard_score(df1['satisfaction'], y_pred, average='weighted')\n",
        "\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "\n",
        "print(f'Adjusted Rand Index (ARI): {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Count the number of data points in each cluster\n",
        "cluster_counts = pd.Series(y_pred).value_counts().sort_index()\n",
        "print('Number of data points in each cluster:')\n",
        "print(cluster_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert Pandas DataFrame to NumPy array\n",
        "X_np = X_scaled.values\n",
        "\n",
        "# Create a 3D scatter plot with Plotly Express\n",
        "fig = px.scatter_3d(\n",
        "    x=X_np[:, 0],\n",
        "    y=X_np[:, 1],\n",
        "    z=X_np[:, 2],\n",
        "    color=y_pred,\n",
        "    labels={'color': 'Cluster'},\n",
        "    title='3D Clustering Visualization (K-Means)',\n",
        "    opacity=0.7,           # Set opacity for better visibility of overlapping points\n",
        "    size_max=15,           # Adjust the maximum marker size\n",
        "    template='plotly_dark',  # Choose a plotly template (e.g., 'plotly', 'plotly_dark', 'plotly_white')\n",
        "    color_continuous_scale='Viridis',  # Choose a color scale (e.g., 'Viridis', 'Jet', 'Plasma')\n",
        "    width=800,             # Set plot width\n",
        "    height=600,            # Set plot height\n",
        ")\n",
        "\n",
        "# Customize the layout (optional)\n",
        "fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='DPD',\n",
        "        yaxis_title='Total_Score',\n",
        "        zaxis_title='Age',\n",
        "        aspectmode='cube',  # Set aspect mode for equal scaling\n",
        "        camera=dict(\n",
        "            eye=dict(x=1.5, y=1.5, z=1.5)  # Adjust the camera position for better viewing\n",
        "        )  \n",
        "    ),\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert Pandas DataFrame to NumPy array\n",
        "X_np = X_scaled.values\n",
        "\n",
        "# Create a 3D scatter plot with Plotly Express\n",
        "fig = px.scatter_3d(\n",
        "    x=X_np[:, 0],\n",
        "    y=X_np[:, 1],\n",
        "    z=X_np[:, 2],\n",
        "    color=y_pred,\n",
        "    labels={'color': 'Cluster'},\n",
        "    title='3D Clustering Visualization (K-Means)',\n",
        "    opacity=0.7,           # Set opacity for better visibility of overlapping points\n",
        "    size_max=15,           # Adjust the maximum marker size\n",
        "    template='plotly_dark',  # Choose a plotly template (e.g., 'plotly', 'plotly_dark', 'plotly_white')\n",
        "    color_continuous_scale='Viridis',  # Choose a color scale (e.g., 'Viridis', 'Jet', 'Plasma')\n",
        "    width=800,             # Set plot width\n",
        "    height=600,            # Set plot height\n",
        ")\n",
        "\n",
        "# Customize the layout (optional)\n",
        "fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='D*D',\n",
        "        yaxis_title='Total_Score',\n",
        "        zaxis_title='Age',\n",
        "        aspectmode='cube',  # Set aspect mode for equal scaling\n",
        "        camera=dict(\n",
        "            eye=dict(x=1.5, y=1.5, z=1.5)  # Adjust the camera position for better viewing\n",
        "        )  \n",
        "    ),\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  X_scaled is  standardized data\n",
        "X_scaled = X1\n",
        "neigh = NearestNeighbors(n_neighbors=2)\n",
        "nbrs = neigh.fit(X_scaled)\n",
        "distances, indices = nbrs.kneighbors(X_scaled)\n",
        "\n",
        "distances = np.sort(distances, axis=0)\n",
        "distances = distances[:, 1]\n",
        "\n",
        "plt.plot(distances)\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance to 2nd Nearest Neighbor')\n",
        "plt.title('Elbow Method for DBSCAN eps')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "X_scaled = X1\n",
        "y = df1['satisfaction']  #  'satisfaction' is the target variable\n",
        "\n",
        "# Varying values for eps and min_samples\n",
        "eps_values = [0.05 , 0.06 , 0.07 , 0.08 , 0.09 , 0.1]\n",
        "min_samples_values = [2, 3, 4]\n",
        "\n",
        "best_eps = None\n",
        "best_min_samples = None\n",
        "best_silhouette_score = -1\n",
        "\n",
        "# Iterate through parameter combinations\n",
        "for eps in eps_values:\n",
        "    for min_samples in min_samples_values:\n",
        "        # Initialize DBSCAN clustering\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        labels = dbscan.fit_predict(X_scaled)\n",
        "        \n",
        "        # Evaluate clustering performance using silhouette score\n",
        "        silhouette = silhouette_score(X_scaled, labels)\n",
        "        \n",
        "        # Print silhouette score for each parameter combination\n",
        "        print(f'eps={eps}, min_samples={min_samples}, Silhouette Score: {silhouette}')\n",
        "        \n",
        "        # Update best parameters if a higher silhouette score is achieved\n",
        "        if silhouette > best_silhouette_score:\n",
        "            best_eps = eps\n",
        "            best_min_samples = min_samples\n",
        "            best_silhouette_score = silhouette\n",
        "\n",
        "# Print the best parameters\n",
        "print(f'Best Parameters: eps={best_eps}, min_samples={best_min_samples}, Best Silhouette Score: {best_silhouette_score}')\n",
        "\n",
        "# Apply DBSCAN with the best parameters\n",
        "best_dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
        "best_labels = best_dbscan.fit_predict(X_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "eps=0.01, min_samples=2, Silhouette Score: 0.438025828350863\n",
        "eps=0.01, min_samples=3, Silhouette Score: 0.41871060744020394\n",
        "eps=0.01, min_samples=4, Silhouette Score: 0.4077674735204568\n",
        "eps=0.02, min_samples=2, Silhouette Score: -0.5953789357856237\n",
        "eps=0.02, min_samples=3, Silhouette Score: -0.5745465962869623\n",
        "eps=0.02, min_samples=4, Silhouette Score: -0.5650357410041018\n",
        "eps=0.03, min_samples=2, Silhouette Score: -0.36541525484261\n",
        "eps=0.03, min_samples=3, Silhouette Score: -0.3012610314189669\n",
        "eps=0.03, min_samples=4, Silhouette Score: -0.20222824767499073\n",
        "eps=0.04, min_samples=2, Silhouette Score: -0.16010032060326204\n",
        "eps=0.04, min_samples=3, Silhouette Score: -0.030513750415238346\n",
        "eps=0.04, min_samples=4, Silhouette Score: 0.06319758079191402\n",
        "eps=0.05, min_samples=2, Silhouette Score: 0.037731286410677786\n",
        "eps=0.05, min_samples=3, Silhouette Score: 0.1044823054291336\n",
        "eps=0.05, min_samples=4, Silhouette Score: 0.19523143620025368\n",
        "Best Parameters: eps=0.01, min_samples=2, Best Silhouette Score: 0.438025828350863"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "X_scaled = X1\n",
        "y = df1['satisfaction']  #  'satisfaction' is the target variable\n",
        "\n",
        "# Varying values for eps and min_samples\n",
        "eps_values = [0.01, 0.02, 0.03, 0.04, 0.05]\n",
        "min_samples_values = [2, 3, 4, 5, 6]\n",
        "\n",
        "best_eps = None\n",
        "best_min_samples = None\n",
        "best_dbi = float('inf')  # Initialize to a high value\n",
        "\n",
        "# Iterate through parameter combinations\n",
        "for eps in eps_values:\n",
        "    for min_samples in min_samples_values:\n",
        "        # Initialize DBSCAN clustering\n",
        "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "        labels = dbscan.fit_predict(X_scaled)\n",
        "        \n",
        "        # Evaluate clustering performance using Davies-Bouldin Index\n",
        "        dbi = davies_bouldin_score(X_scaled, labels)\n",
        "        \n",
        "        # Print Davies-Bouldin Index for each parameter combination\n",
        "        print(f'eps={eps}, min_samples={min_samples}, Davies-Bouldin Index: {dbi}')\n",
        "        \n",
        "        # Update best parameters if a lower Davies-Bouldin Index is achieved\n",
        "        if dbi < best_dbi:\n",
        "            best_eps = eps\n",
        "            best_min_samples = min_samples\n",
        "            best_dbi = dbi\n",
        "\n",
        "# Print the best parameters\n",
        "print(f'Best Parameters: eps={best_eps}, min_samples={best_min_samples}, Best Davies-Bouldin Index: {best_dbi}')\n",
        "\n",
        "# Apply DBSCAN with the best parameters\n",
        "best_dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
        "best_labels = best_dbscan.fit_predict(X_scaled)\n",
        "\n",
        "# Visualize or further analyze the clusters obtained with the best parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import adjusted_rand_score\n",
        "\n",
        "#  X1 is  DataFrame with the selected columns\n",
        "X_scaled = X1\n",
        "y = df1['satisfaction']  #  'satisfaction' is the target variable\n",
        "\n",
        "min_samples_values = [3, 5, 7, 10]  # Adjustting the range based on data\n",
        "eps = 0.025  # Adjust the epsilon value\n",
        "\n",
        "best_score = -1\n",
        "best_min_samples = None\n",
        "\n",
        "for min_samples in min_samples_values:\n",
        "    dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    labels = dbscan.fit_predict(X_scaled)\n",
        "    score = adjusted_rand_score(y, labels)\n",
        "    print(f'Min Samples: {min_samples}, Adjusted Rand Score: {score}')\n",
        "\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_min_samples = min_samples\n",
        "\n",
        "print(f'Best Min Samples: {best_min_samples}, Best Adjusted Rand Score: {best_score}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Setting the parameters for DBSCAN\n",
        "eps = 0.025  # Adjust based on  data\n",
        "min_samples = 3  # Adjust based on  data\n",
        "\n",
        "# Initialize DBSCAN clustering\n",
        "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "labels = dbscan.fit_predict(X_scaled)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "dbi = davies_bouldin_score(X_scaled, labels)\n",
        "silhouette = silhouette_score(X_scaled, labels)\n",
        "chs = calinski_harabasz_score(X_scaled, labels)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], labels)\n",
        "jaccard = jaccard_score(df1['satisfaction'], labels, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "print(f'Adjusted Rand Index: {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  'best_labels' is the cluster labels obtained from DBSCAN\n",
        "unique_labels, counts = np.unique(best_labels, return_counts=True)\n",
        "\n",
        "# Display counts for each class\n",
        "for label, count in zip(labels, counts):\n",
        "    print(f'Class {label}: {count} points')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hierarchical (Kernel crashed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#  X is  feature matrix and Z is the linkage matrix\n",
        "X = X1 [['DPD','Total_Score']]\n",
        "\n",
        "Z = linkage(X, method='ward')\n",
        "plt.figure(figsize=(12, 6))\n",
        "dendrogram(Z)\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score, jaccard_score\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "\n",
        "#  X is  feature matrix\n",
        "X = df1.drop('satisfaction', axis=1)\n",
        "\n",
        "# Perform hierarchical clustering\n",
        "Z = linkage(X, method='ward')\n",
        "\n",
        "# Set the number of clusters (you can choose based on dendrogram)\n",
        "n_clusters = 3\n",
        "\n",
        "# Fit AgglomerativeClustering model\n",
        "model = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "labels = model.fit_predict(X)\n",
        "\n",
        "# Evaluate clustering performance\n",
        "silhouette = silhouette_score(X, labels)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], labels)\n",
        "jaccard = jaccard_score(df1['satisfaction'], labels, average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Adjusted Rand Index: {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n",
        "\n",
        "# Visualize dendrogram\n",
        "plt.figure(figsize=(12, 6))\n",
        "dendrogram(Z)\n",
        "plt.title('Hierarchical Clustering Dendrogram')\n",
        "plt.xlabel('Data Points')\n",
        "plt.ylabel('Distance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "BRICH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import Birch\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import numpy as np\n",
        "\n",
        "#  X1 is  DataFrame with the selected columns\n",
        "X_scaled = X1\n",
        "y = df1['satisfaction']  #  'satisfaction' is the target variable\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'threshold': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "    'branching_factor': [10, 20, 30, 40, 50]\n",
        "}\n",
        "\n",
        "# Generate all combinations of hyperparameters\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_params = None\n",
        "best_dbi = float('inf')  # Initialize to a high value\n",
        "\n",
        "# Iterate through parameter combinations\n",
        "for params in param_combinations:\n",
        "    # Initialize BIRCH clustering with current hyperparameters\n",
        "    birch = Birch(**params)\n",
        "    labels = birch.fit_predict(X_scaled)\n",
        "    \n",
        "    # Check if there are more than one unique label (cluster)\n",
        "    unique_labels = np.unique(labels)\n",
        "    if len(unique_labels) > 1:\n",
        "        # Evaluate clustering performance using Davies-Bouldin Index\n",
        "        dbi = davies_bouldin_score(X_scaled, labels)\n",
        "        \n",
        "        # Print evaluation metrics for each parameter combination\n",
        "        print(f'Parameters: {params}')\n",
        "        print(f'Davies-Bouldin Index: {dbi}')\n",
        "        \n",
        "        # Update best parameters if a lower Davies-Bouldin Index is achieved\n",
        "        if dbi < best_dbi:\n",
        "            best_params = params\n",
        "            best_dbi = dbi\n",
        "\n",
        "# Print the best parameters\n",
        "print(f'Best Parameters: {best_params}, Best Davies-Bouldin Index: {best_dbi}')\n",
        "\n",
        "# Apply BIRCH with the best parameters\n",
        "best_birch = Birch(**best_params)\n",
        "best_labels = best_birch.fit_predict(X_scaled)\n",
        "\n",
        "# Visualize or further analyze the clusters obtained with the best parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "\n",
        "#  'best_labels' is the cluster labels obtained from BIRCH\n",
        "\n",
        "# Evaluate clustering performance using Davies-Bouldin Index, Silhouette Score, Calinski-Harabasz Score, Adjusted Rand Index, and Jaccard Score\n",
        "dbi = davies_bouldin_score(X_scaled, best_labels)\n",
        "silhouette = silhouette_score(X_scaled, best_labels)\n",
        "chs = calinski_harabasz_score(X_scaled, best_labels)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], best_labels)\n",
        "jaccard = jaccard_score(df1['satisfaction'], best_labels, average='weighted')\n",
        "\n",
        "# Print evaluation metrics after fitting the model\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "print(f'Adjusted Rand Index: {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "#  'best_labels' contains the cluster labels obtained from BIRCH or any clustering algorithm\n",
        "#  'X_scaled' is  preprocessed and scaled data\n",
        "\n",
        "# Convert Pandas DataFrame to NumPy array\n",
        "X_np = X_scaled.values\n",
        "\n",
        "# Create a 3D scatter plot with Plotly Express\n",
        "fig = px.scatter_3d(\n",
        "    x=X_np[:, 0],\n",
        "    y=X_np[:, 1],\n",
        "    z=X_np[:, 2],\n",
        "    color=best_labels,\n",
        "    labels={'color': 'Cluster'},\n",
        "    title='3D Clustering Visualization',\n",
        "    opacity=0.7,           # Set opacity for better visibility of overlapping points\n",
        "    size_max=15,           # Adjust the maximum marker size\n",
        "    template='plotly_dark',  # Choose a plotly template (e.g., 'plotly', 'plotly_dark', 'plotly_white')\n",
        "    color_continuous_scale='Viridis',  # Choose a color scale (e.g., 'Viridis', 'Jet', 'Plasma')\n",
        "    width=800,             # Set plot width\n",
        "    height=600,            # Set plot height\n",
        ")\n",
        "\n",
        "# Customize the layout (optional)\n",
        "fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='DPD',\n",
        "        yaxis_title='Total_Score',\n",
        "        zaxis_title='Age',\n",
        "        aspectmode='cube',  # Set aspect mode for equal scaling\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Fuzzy C-Means (FCM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "from skfuzzy.cluster import cmeans\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "\n",
        "#  X1 is  DataFrame with the selected columns\n",
        "X_scaled = X1.values\n",
        "y = df1['satisfaction']  #  'satisfaction' is the target variable\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'c': [1, 2, 3, 4, 5],     # Number of clusters\n",
        "    'm': [1.1, 1.5, 2.0, 2.5],  # Fuzziness parameter\n",
        "    'error': [0.001, 0.01, 0.1, 0.5],  # Tolerance to stop iteration\n",
        "    'maxiter': [50, 100, 150],  # Maximum number of iterations\n",
        "}\n",
        "\n",
        "# Generate all combinations of hyperparameters\n",
        "param_combinations = list(ParameterGrid(param_grid))\n",
        "\n",
        "best_params = None\n",
        "best_dbi = float('inf')  # Initialize to a high value\n",
        "\n",
        "# Iterate through parameter combinations\n",
        "for params in param_combinations:\n",
        "    # Initialize FCM clustering with current hyperparameters\n",
        "    cntr, u, _, _, _, _, _ = cmeans(X_scaled.T, params['c'], params['m'], error=params['error'], maxiter=params['maxiter'])\n",
        "    \n",
        "    # Get cluster labels based on the highest membership values\n",
        "    labels = np.argmax(u, axis=0)\n",
        "    \n",
        "    # Check if the number of unique labels is greater than 1\n",
        "    if len(np.unique(labels)) <= 1:\n",
        "        continue\n",
        "    \n",
        "    # Evaluate clustering performance using Davies-Bouldin Index\n",
        "    dbi = davies_bouldin_score(X_scaled, labels)\n",
        "    \n",
        "    # Print evaluation metrics for each parameter combination\n",
        "    print(f'Parameters: {params}')\n",
        "    print(f'Davies-Bouldin Index: {dbi}')\n",
        "    \n",
        "    # Update best parameters if a lower Davies-Bouldin Index is achieved\n",
        "    if dbi < best_dbi:\n",
        "        best_params = params\n",
        "        best_dbi = dbi\n",
        "\n",
        "# Print the best parameters\n",
        "print(f'Best Parameters: {best_params}, Best Davies-Bouldin Index: {best_dbi}')\n",
        "\n",
        "# Apply FCM with the best parameters\n",
        "best_cntr, best_u, _, _, _, _, _ = cmeans(X_scaled.T, best_params['c'], best_params['m'], error=best_params['error'], maxiter=best_params['maxiter'])\n",
        "best_labels = np.argmax(best_u, axis=0)\n",
        "\n",
        "# Visualize or further analyze the clusters obtained with the best parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import davies_bouldin_score, silhouette_score, calinski_harabasz_score, adjusted_rand_score, jaccard_score\n",
        "\n",
        "#  'best_labels' is the cluster labels obtained from  Fuzzy C-Means (FCM)\n",
        "\n",
        "# Evaluate clustering performance using Davies-Bouldin Index, Silhouette Score, Calinski-Harabasz Score, Adjusted Rand Index, and Jaccard Score\n",
        "dbi = davies_bouldin_score(X_scaled, best_labels)\n",
        "silhouette = silhouette_score(X_scaled, best_labels)\n",
        "chs = calinski_harabasz_score(X_scaled, best_labels)\n",
        "ari = adjusted_rand_score(df1['satisfaction'], best_labels)\n",
        "jaccard = jaccard_score(df1['satisfaction'], best_labels, average='weighted')\n",
        "\n",
        "# Print evaluation metrics after fitting the model\n",
        "print(f'Davies-Bouldin Index: {dbi}')\n",
        "print(f'Silhouette Score: {silhouette}')\n",
        "print(f'Calinski-Harabasz Score: {chs}')\n",
        "print(f'Adjusted Rand Index: {ari}')\n",
        "print(f'Jaccard Score: {jaccard}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Create a 3D scatter plot with Plotly Express\n",
        "fig = px.scatter_3d(\n",
        "    x=X_np[:, 0],\n",
        "    y=X_np[:, 1],\n",
        "    z=X_np[:, 2],\n",
        "    color=best_labels,\n",
        "    labels={'color': 'Cluster'},\n",
        "    title='3D Clustering Visualization',\n",
        "    opacity=0.7,           # Set opacity for better visibility of overlapping points\n",
        "    size_max=15,           # Adjust the maximum marker size\n",
        "    template='plotly_dark',  # Choose a Plotly template (e.g., 'plotly', 'plotly_dark', 'plotly_white')\n",
        "    color_continuous_scale='Viridis',  # Choose a color scale (e.g., 'Viridis', 'Jet', 'Plasma')\n",
        "    width=800,             # Set plot width\n",
        "    height=600,            # Set plot height\n",
        ")\n",
        "\n",
        "# Customize the layout (optional)\n",
        "fig.update_layout(\n",
        "    scene=dict(\n",
        "        xaxis_title='DPD',\n",
        "        yaxis_title='Total_Score',\n",
        "        zaxis_title='Age',\n",
        "        aspectmode='cube',  # Set aspect mode for equal scaling\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
